{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800f300e-1c9d-4f8e-9bce-aa31778a3bbc",
   "metadata": {},
   "source": [
    "# Capstone: Exploratory Prediction Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b05fd2b-87c4-4db0-9bb5-1ae0748656bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Import utilities\n",
    "# import pathlib\n",
    "import time\n",
    "\n",
    "# Export dataFrame's as images\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# import project utils\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import data_utils\n",
    "from data_utils import Config\n",
    "\n",
    "import graph_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, log_loss\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4214fe9c-8a7e-46d6-a79e-48fe4150289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c6b335-5290-483d-8aa6-5b7f9b7b5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_secs_to_msg(lapse_time_secs, mins_label='m', secs_label='s'):\n",
    "    if lapse_time_secs <= 60:\n",
    "        return f'{lapse_time_secs%60:.2f}{secs_label}'\n",
    "    else:\n",
    "        return f'{lapse_time_secs//60:,.0f}{mins_label} {lapse_time_secs%60:.2f}{secs_label}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814d6a5-3ae8-43f1-b00f-5b22986f3267",
   "metadata": {},
   "source": [
    "## The Data: San Francisco Police Department Incident Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd64605-3a3b-480b-be39-711b70beb7cc",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3250ab5b-8240-4f47-9438-aecea04d69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sample file: ../data/incidents_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Which dataset to work from?\n",
    "\n",
    "sample_file = data_utils.select_sample_csv_file(pct=100)\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=10)\n",
    "print(f'Selected sample file: {sample_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f7eb17-698f-4eba-aebc-c2893f443e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ../data/incidents_clean.csv ... Done: 894,585 rows, 36 columns\n",
      "... Converting datetime to timeseries ... Done\n",
      "... Setting index to datetime ... Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "current_raw_df, current_clean_df = data_utils.get_clean_data_from_csv(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49438aea-557f-49a0-9caf-2a230ea378f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing ... \n",
      "... Dropping unwanted columns ... \n",
      "... preprocess_drop_cols: Column Unnamed: 0 not dropped: KeyError(\"['Unnamed: 0'] not found in axis\")\n",
      "... preprocess_drop_cols: Column esncag_-_boundary_file dropped\n",
      "... preprocess_drop_cols: Column central_market/tenderloin_boundary_polygon_-_updated dropped\n",
      "... preprocess_drop_cols: Column civic_center_harm_reduction_project_boundary dropped\n",
      "... preprocess_drop_cols: Column hsoc_zones_as_of_2018-06-05 dropped\n",
      "... preprocess_drop_cols: Column invest_in_neighborhoods_(iin)_areas dropped\n",
      "... preprocess_drop_cols: Column report_type_code dropped\n",
      "... preprocess_drop_cols: Column report_type_description dropped\n",
      "... preprocess_drop_cols: Column filed_online dropped\n",
      "... preprocess_drop_cols: Column intersection dropped\n",
      "... preprocess_drop_cols: Column cnn dropped\n",
      "... preprocess_drop_cols: Column point dropped\n",
      "... preprocess_drop_cols: Column supervisor_district dropped\n",
      "... preprocess_drop_cols: Column supervisor_district_2012 dropped\n",
      "... preprocess_drop_cols: Column current_supervisor_districts dropped\n",
      "... preprocess_drop_cols: Column incident_datetime dropped\n",
      "... preprocess_drop_cols: Column report_datetime dropped\n",
      "... preprocess_drop_cols: Column incident_id dropped\n",
      "... preprocess_drop_cols: Column incident_code dropped\n",
      "... preprocess_drop_cols: Column row_id dropped\n",
      "... preprocess_drop_cols: Column incident_number dropped\n",
      "... preprocess_drop_cols: Column cad_number dropped\n",
      "... preprocess_drop_cols: Column incident_subcategory dropped\n",
      "... preprocess_drop_cols: Column incident_description dropped\n",
      "... preprocess_drop_cols: Column current_police_districts dropped\n",
      "... preprocess_drop_cols: Column neighborhoods dropped\n",
      "... Done\n",
      "... Removing resolution types: \"Unfounded\", \"Exceptional Adult\" ... \n",
      "... Removing police_district types: \"Out of SF\" ... \n",
      "... Renaming column: \"analysis_neighborhood\" -> \"neighborhood\" ... \n",
      "... Renaming columns: Dropping \"incident_*\" from column names ... \n",
      "... Removing rows with nulls (dropna) ... \n",
      "... Done\n",
      "Done: Start: (894585, 35), End: (829328, 10) -> Rows removed: 65,257 rows (7.29%)\n"
     ]
    }
   ],
   "source": [
    "data = data_utils.preprocess_data(current_raw_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796600d8-4dc4-4367-8bdd-48602641b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data artifacts (in-place) ... \n",
      "... Category column:\n",
      "    ...\"Human Trafficking*\"\n",
      "    ...\"Motor Vehicle Theft\"\n",
      "    ...\"Weapons Offence\"\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Fix data value artifacts that were discovered during EDA\n",
    "data = data_utils.fix_data_artifacts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0593a1a6-d608-4168-ab60-698d8e3a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 829328 entries, 2023-03-11 14:00:00 to 2023-03-21 17:42:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   date             829328 non-null  object \n",
      " 1   time             829328 non-null  object \n",
      " 2   year             829328 non-null  int64  \n",
      " 3   day_of_week      829328 non-null  object \n",
      " 4   category         829328 non-null  object \n",
      " 5   resolution       829328 non-null  object \n",
      " 6   police_district  829328 non-null  object \n",
      " 7   neighborhood     829328 non-null  object \n",
      " 8   latitude         829328 non-null  float64\n",
      " 9   longitude        829328 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 69.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b6f7-2f63-409e-8a77-d95a82a599b2",
   "metadata": {},
   "source": [
    "## Summary of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62469-b0fa-405b-ae5e-9cf32c9994a4",
   "metadata": {},
   "source": [
    "After cleaning the data and performing basic EDA, we have established the following:\n",
    "\n",
    "1. Target variable `category`\n",
    "   * Evenly spread across time\n",
    "   * Incidence of crimes is extremely skewed/unbalanced by category. Larceny (29.02%) by far outweighing the other top-10 categories with each being in the single digits\n",
    "3. Features impacting `category`\n",
    "   * Affected by incident time and date components: date, time, day of week, month, year, etc\n",
    "   * Affected by police disctrict\n",
    "   * Affect by latitude and logitude (TODO: need visualization)\n",
    "4. We artificially removed nulls (TODO: will come back to impute data later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4580fda-167c-419e-94a4-466d884169d8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3693b1c-6a4c-4480-99c3-1afb183a1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>category</th>\n",
       "      <th>resolution</th>\n",
       "      <th>police_district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-11 14:00:00</th>\n",
       "      <td>2023/03/11</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Assault</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Park</td>\n",
       "      <td>Golden Gate Park</td>\n",
       "      <td>37.772895</td>\n",
       "      <td>-122.454285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27 12:00:00</th>\n",
       "      <td>2022/06/27</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Lost Property</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Central</td>\n",
       "      <td>Financial District/South Beach</td>\n",
       "      <td>37.787359</td>\n",
       "      <td>-122.408227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date   time  year day_of_week       category  \\\n",
       "datetime                                                                  \n",
       "2023-03-11 14:00:00  2023/03/11  14:00  2023    Saturday        Assault   \n",
       "2022-06-27 12:00:00  2022/06/27  12:00  2022      Monday  Lost Property   \n",
       "\n",
       "                         resolution police_district  \\\n",
       "datetime                                              \n",
       "2023-03-11 14:00:00  Open or Active            Park   \n",
       "2022-06-27 12:00:00  Open or Active         Central   \n",
       "\n",
       "                                       neighborhood   latitude   longitude  \n",
       "datetime                                                                    \n",
       "2023-03-11 14:00:00                Golden Gate Park  37.772895 -122.454285  \n",
       "2022-06-27 12:00:00  Financial District/South Beach  37.787359 -122.408227  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c52ff3-baa7-47e8-95e7-6b65ffd9424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 829328 entries, 2023-03-11 14:00:00 to 2023-03-21 17:42:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   date             829328 non-null  object \n",
      " 1   time             829328 non-null  object \n",
      " 2   year             829328 non-null  int64  \n",
      " 3   day_of_week      829328 non-null  object \n",
      " 4   category         829328 non-null  object \n",
      " 5   resolution       829328 non-null  object \n",
      " 6   police_district  829328 non-null  object \n",
      " 7   neighborhood     829328 non-null  object \n",
      " 8   latitude         829328 non-null  float64\n",
      " 9   longitude        829328 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 69.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93db1b-4718-4bac-8a22-8aff944c3c64",
   "metadata": {},
   "source": [
    "### Encoding: Time-based columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6939cb5-85c3-4f3e-92f8-23347859bded",
   "metadata": {},
   "source": [
    "Let's unpack the date and time into their components that are still missing so there is less to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e80e1ca0-445e-4251-8672-a70c5ef40597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour'] = data.index.map(lambda x: x.hour)\n",
    "data['minute'] = data.index.map(lambda x: x.minute)\n",
    "data['day'] = data.index.map(lambda x: x.day)\n",
    "data['month'] = data.index.map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834113f-4129-4c28-9ca6-f2f5051b7b1e",
   "metadata": {},
   "source": [
    "Now let's encode day_of_week to numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba3c50f-bc77-4491-b663-4ea286c5774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dow = LabelEncoder()\n",
    "enc_dow.fit(data.day_of_week.unique())\n",
    "data['dow'] = enc_dow.transform(data.day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb03a71-9c9e-4bca-af32-b35f05db2e1e",
   "metadata": {},
   "source": [
    "Let's mark the redundant columns to be dropped after feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce4c19a-dbf1-49c6-8fc5-c91a4e72aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols = ['date', 'time', 'day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474b64-0486-4de0-9fe3-85dd1df87559",
   "metadata": {},
   "source": [
    "### Encoding: Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fb531-2e4c-4f36-bf09-00bc9ca6c0e3",
   "metadata": {},
   "source": [
    "We will also drop the resolution column since it doesn't impact crime prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d130971c-9f96-40c2-a973-bb5ada873544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolution\n",
       "Open or Active          662581\n",
       "Cite or Arrest Adult    166747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.resolution.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b60a7a-4290-42c5-bdcc-12436361160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols.append('resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a27a2a-a4e1-46e6-aaaa-6462a88ef904",
   "metadata": {},
   "source": [
    "### Encoding: Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1887058d-290d-4de7-be1a-ad4790edc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cat = LabelEncoder()\n",
    "enc_cat.fit(data.category.unique())\n",
    "data.category = enc_cat.transform(data.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4357e80-34aa-426c-8360-15da700f3136",
   "metadata": {},
   "source": [
    "### Encoding: Police District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b918e7f-285b-4cd6-9960-7fe80b848c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pd = LabelEncoder()\n",
    "enc_pd.fit(data.police_district.unique())\n",
    "data['pd'] = enc_pd.transform(data.police_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b758e-6f91-45af-b590-f526a8d84033",
   "metadata": {},
   "source": [
    "### Encoding: Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82fb1300-2f74-4930-94ab-a5b161e4b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hood = LabelEncoder()\n",
    "enc_hood.fit(data.neighborhood.unique())\n",
    "data.neighborhood = enc_hood.transform(data.neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844c0b5-1967-46f3-b316-5f8e2a1e4e74",
   "metadata": {},
   "source": [
    "### Dropping Redundant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40759752-bd7b-40ee-9503-2778c2594c9f",
   "metadata": {},
   "source": [
    "We can now drop the redundant encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db644549-7780-4117-be95-207dde3eb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping encoded columns: ['date', 'time', 'day_of_week', 'resolution', 'police_district']\n"
     ]
    }
   ],
   "source": [
    "drop_encoded_cols.append('police_district')\n",
    "\n",
    "print(f'Dropping encoded columns: {drop_encoded_cols}')\n",
    "data.drop(columns=drop_encoded_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de363da7-290a-4a98-bee6-2760db2cb526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>pd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-11 14:00:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>37.772895</td>\n",
       "      <td>-122.454285</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27 12:00:00</th>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>37.787359</td>\n",
       "      <td>-122.408227</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  category  neighborhood   latitude   longitude  \\\n",
       "datetime                                                                   \n",
       "2023-03-11 14:00:00  2023         1             7  37.772895 -122.454285   \n",
       "2022-06-27 12:00:00  2022        18             5  37.787359 -122.408227   \n",
       "\n",
       "                     hour  minute  day  month  dow  pd  \n",
       "datetime                                                \n",
       "2023-03-11 14:00:00    14       0   11      3    2   5  \n",
       "2022-06-27 12:00:00    12       0   27      6    1   1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a45dd9e-7aa0-43c1-9d94-40d6287cb845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 829328 entries, 2023-03-11 14:00:00 to 2023-03-21 17:42:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   year          829328 non-null  int64  \n",
      " 1   category      829328 non-null  int64  \n",
      " 2   neighborhood  829328 non-null  int64  \n",
      " 3   latitude      829328 non-null  float64\n",
      " 4   longitude     829328 non-null  float64\n",
      " 5   hour          829328 non-null  int64  \n",
      " 6   minute        829328 non-null  int64  \n",
      " 7   day           829328 non-null  int64  \n",
      " 8   month         829328 non-null  int64  \n",
      " 9   dow           829328 non-null  int64  \n",
      " 10  pd            829328 non-null  int64  \n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 75.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7ab2c-d5a3-4d2a-b158-87ea45debe21",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d496dcd-171a-4d49-8807-11ffafa4b233",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac470dae-d362-45d4-911f-5906ce1e271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('category', axis='columns')\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9df7a80e-6033-412d-a282-ffa985f48904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode the features and drop the first value to reduce multicollinearity\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "140d725c-be87-47fd-b60d-6bee9e666ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project-wide random_state: 42\n"
     ]
    }
   ],
   "source": [
    "# Consistent random_state for the project\n",
    "print(f'Project-wide random_state: {Config.RANDOM_STATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f71f3ab-33fa-4ea3-bade-efc053e13870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=Config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1966aa94-1593-4fd3-a9af-f4501f0fa543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER TRAIN_TEST_SPLIT: Data(829328, 11), X_train(663462, 10), X_test(165866, 10), y_train(663462,), y_test(165866,)\n"
     ]
    }
   ],
   "source": [
    "print('AFTER TRAIN_TEST_SPLIT: Data{}, X_train{}, X_test{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a01d3fc6-d194-43b3-89eb-aa639586aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>datetime</th>\n",
       "      <th>2023-03-11 14:00:00</th>\n",
       "      <th>2022-06-27 12:00:00</th>\n",
       "      <th>2023-03-16 17:30:00</th>\n",
       "      <th>2023-03-21 15:50:00</th>\n",
       "      <th>2021-08-22 09:40:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>37.772895</td>\n",
       "      <td>37.787359</td>\n",
       "      <td>37.762290</td>\n",
       "      <td>37.787038</td>\n",
       "      <td>37.793977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-122.454285</td>\n",
       "      <td>-122.408227</td>\n",
       "      <td>-122.401324</td>\n",
       "      <td>-122.418271</td>\n",
       "      <td>-122.429804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "datetime      2023-03-11 14:00:00  2022-06-27 12:00:00  2023-03-16 17:30:00  \\\n",
       "year                  2023.000000          2022.000000          2023.000000   \n",
       "neighborhood             7.000000             5.000000            28.000000   \n",
       "latitude                37.772895            37.787359            37.762290   \n",
       "longitude             -122.454285          -122.408227          -122.401324   \n",
       "hour                    14.000000            12.000000            17.000000   \n",
       "minute                   0.000000             0.000000            30.000000   \n",
       "day                     11.000000            27.000000            16.000000   \n",
       "month                    3.000000             6.000000             3.000000   \n",
       "dow                      2.000000             1.000000             4.000000   \n",
       "pd                       5.000000             1.000000             0.000000   \n",
       "\n",
       "datetime      2023-03-21 15:50:00  2021-08-22 09:40:00  \n",
       "year                  2023.000000          2021.000000  \n",
       "neighborhood            35.000000            26.000000  \n",
       "latitude                37.787038            37.793977  \n",
       "longitude             -122.418271          -122.429804  \n",
       "hour                    15.000000             9.000000  \n",
       "minute                  50.000000            40.000000  \n",
       "day                     21.000000            22.000000  \n",
       "month                    3.000000             8.000000  \n",
       "dow                      5.000000             3.000000  \n",
       "pd                       4.000000             4.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot-check feature encoding\n",
    "X.T.iloc[:, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ffce7-ac24-4443-a5df-81a0449852c6",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6ed9a74-008a-4c0f-b2af-76e5f0e54793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER SCALING: Data(829328, 11), X_train_scaled(663462, 10), X_test_scaled(165866, 10), y_train(663462,), y_test(165866,)\n"
     ]
    }
   ],
   "source": [
    "# Scale the data - we'll use StandardScaler for the baseline model\n",
    "logging.debug('Scaling data')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('AFTER SCALING: Data{}, X_train_scaled{}, X_test_scaled{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df8b27-6969-4b14-b3e0-f4e351df67d0",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a3fbc-b034-4ced-a667-57713c0453a4",
   "metadata": {},
   "source": [
    "The task of classifying the incident types based on a set of historical attrirbutes (features) and predicting on similar attributes is a **multiclass classification** problem. We will now experiment on some ML models that are generally used for similar problems to see what would be the best choice for us.\n",
    "\n",
    "We will evaluate the following models:\n",
    "\n",
    "* Simple classification models\n",
    "  * `DummyClassifier` to get a baseline for our project\n",
    "  * `LogisticRegression` with L1 Regularization\n",
    "* Multiclass classifiers\n",
    "  * `KNeighborsClassifier`\n",
    "* Ensemble methods: Since our dataset has high variability with a lot of numerical and cagtegorical features with a range of mean and variance, we plan to employ ensemble methods and tune them for best results\n",
    "  * `RandomForestClassifier`\n",
    "  * `XGBClassifier`: We considered `XGLite` but selected XGBoost as it provides better model explainability features like SHAP values, which we expect to be able to use in explaining our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e74d3-390d-4b30-acc2-d685aa461d76",
   "metadata": {},
   "source": [
    "We will now evaluate different models for predicting the Crime Category from our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb217f2-ba53-4f9a-9fdf-c79a3deefe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'neighborhood', 'latitude', 'longitude', 'hour', 'minute',\n",
       "       'day', 'month', 'dow', 'pd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d149f8-5cf7-4455-9d03-e4018d377dd3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98634325-3d11-4c84-af0b-1cf89d0b122a",
   "metadata": {},
   "source": [
    "In this project, we are predicting or classifyig across 49 crime categories. We will use two evaluation metrics to compare our models:\n",
    "\n",
    "1. **Accuracy**: Measures the proportion of correct predictions over all predictions made. The accuracy benchmark is 1/49 or 2.04% given our crime categories\n",
    "2. **Log_Loss**: Measures the accuracy of a classifier by penalizing false classifications. It does this by taking the negative logarithm of the predicted probability for the true class. The goal is to minimize this loss, meaning that higher probabilities are assigned to the correct classes. Log loss is a powerful way to evaluate not just if the model is making the right predictions, but how confident it is in those predictions. A lower log loss indicates a model that is both accurate and confident.\n",
    "   * TODO: Benchmark???\n",
    "\n",
    "While accuracy provides a simple measure of correctness, log-loss offers a more nuanced view by considering how confident those predictions are. A model that predicts with 51% confidence for the correct class will have the same accuracy as one that predicts with 99% confidence, but their log loss will be very different. The 99%-confident model will have a much lower log loss.\n",
    "\n",
    "We'll use them together for a comprehensive evaluation and to learn more about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b0add-d301-47ef-afaf-781d93e3baba",
   "metadata": {},
   "source": [
    "The `build_results_row` utility function will be used to standardize the recording and reporting of our model exploration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d907e6-792a-4c8b-bd67-a4818a4a1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_row(name, model, Xtr, Xte, ytr, yte, use_best=False):\n",
    "    \"\"\"\n",
    "    Given the model and training/test sets, builds a row of metrics for reporting the results\n",
    "\n",
    "    :param name: Name/Description of model\n",
    "    :param model: Fully constructed model instance - will call fit() and predict() to get metrics\n",
    "    :param Xtr: X_train - scale before calling\n",
    "    :param Xte: X_test - scale before calling\n",
    "    :param ytr: Y_train set\n",
    "    :param yteL: Y_test set\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'{name}: Starting', flush=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(Xtr, ytr)\n",
    "\n",
    "    # if we're tuning then use best_estimator\n",
    "    if use_best:\n",
    "        clf = model.best_estimator_\n",
    "        logging.debug(f'{name}: Best Model={clf}')\n",
    "        logging.debug(f'{name}: Best Params={model.best_params_}')\n",
    "\n",
    "    # Save fit time\n",
    "    fit_time = time.time() - start_time\n",
    "    logging.debug(f'{name}: Fitted')\n",
    "\n",
    "    # get the predictions / probabilities\n",
    "    y_preds = clf.predict(Xte)\n",
    "    y_probs_full = clf.predict_proba(Xte)\n",
    "    y_probs = y_probs_full[:, 1]\n",
    "\n",
    "    # logging.debug(f'>>> yte.shape{yte.shape} y_preds.shape{y_preds.shape} y_probs_full.shape{y_probs_full.shape}')\n",
    "    # logging.debug(f'>>> {np.unique(yte)}')\n",
    "    # logging.debug(f'>>> {np.unique(y_preds)}')\n",
    "    # logging.debug(f'>>> {np.unique(y_probs_full)}')\n",
    "    logging.debug(f'{name}: Got preds/probs')\n",
    "\n",
    "    cm = confusion_matrix(yte, y_preds)\n",
    "    logging.debug(f'{name}: cm.shape: {cm.shape}')\n",
    "\n",
    "    # Get metrics\n",
    "    row = {\n",
    "        'Train Time': time_secs_to_msg(fit_time),\n",
    "        'Train Accuracy': f'{model.score(Xtr, ytr)*100:.2f}%',\n",
    "        'Test Accuracy': f'{model.score(Xte, yte)*100:.2f}%',\n",
    "        'Precision': f'{precision_score(yte, y_preds, average=\"weighted\")*100:.2f}%',  # for multi-class with imbalance\n",
    "        'Recall': f'{recall_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'F1': f'{f1_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'AUC': f'{roc_auc_score(yte, y_probs_full, average=\"weighted\", multi_class=\"ovr\")*100:.2f}%',    # faster with imbalanced multi-class cases\n",
    "        'LogLoss': f'{log_loss(yte, y_probs_full, labels=np.unique(yte)):.4f}',\n",
    "        'preds': y_preds,\n",
    "        'probs': y_probs,\n",
    "        'cm': cm,\n",
    "        # 'TN': f'{cm[0, 0]:,d}',\n",
    "        # 'FP': f'{cm[0, 1]:,d}',\n",
    "        # 'FN': f'{cm[1, 0]:,d}',\n",
    "        # 'TP': f'{cm[1, 1]:,d}',\n",
    "        'params': model.get_params(),\n",
    "        'best_params': None,\n",
    "        'best_model': clf,\n",
    "    }\n",
    "    if use_best:\n",
    "        row.update({'best_params': model.best_params_})\n",
    "        \n",
    "    logging.debug(f'{name}: Got metrics')\n",
    "    \n",
    "    print(f'{name}: Done: {time_secs_to_msg(time.time()-start_time)}')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc07dee-bc84-47e9-9534-8cb45ba5895c",
   "metadata": {},
   "source": [
    "### Establishing a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437c17b-eece-4bc1-ae29-ed0f023056e3",
   "metadata": {},
   "source": [
    "#### DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443338d-fa9b-4c0c-8bd1-e831c3244043",
   "metadata": {},
   "source": [
    "We will use the Scikit-Learn DummyClassifier method to get a baseline for our predictions using the different strategies provided by the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39f421c5-bc59-47db-8b30-f534a18f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5389318-135b-483b-a8a8-7cefd2223b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_defaults = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols = ['Train Time', \n",
    "               'Train Accuracy', 'Test Accuracy', 'LogLoss',\n",
    "               'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c554832-05bd-48c1-b3e3-6ab9a0e8ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DummyClassifier models we want to test\n",
    "models_dummy = {\n",
    "    'DummyClassifier: uniform': DummyClassifier(strategy='uniform', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: most_frequent': DummyClassifier(strategy='most_frequent', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: stratified': DummyClassifier(strategy='stratified', random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7cb9c0f-d499-40b1-bf03-da7978cf2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: uniform: Starting\n",
      "DummyClassifier: uniform: Done: 3.96s\n",
      "DummyClassifier: most_frequent: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: most_frequent: Done: 2.19s\n",
      "DummyClassifier: stratified: Starting\n",
      "DummyClassifier: stratified: Done: 16.75s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_dummy.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aefff5-68d8-4f56-9c4e-932a17b16c7f",
   "metadata": {},
   "source": [
    "The warning above is from the precision calculation within scikit-learn, and highlights that some labels have no predicted samples, which results in precision being undefined for those labels. We can ignore the warning since we're using accuracy as our key evaluation metric. We could use `prescion_score(zero_division=0)` to suppress the warning, but we'll ignore it instead to ensure we're aware of the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e04a9d6-78c2-44c0-be2c-3070b772558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "865380fa-be16-41bf-b432-605606bbfa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e57e2 th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_e57e2 th.col2 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_e57e2_row0_col2, #T_e57e2_row0_col3, #T_e57e2_row1_col2, #T_e57e2_row1_col3, #T_e57e2_row2_col2, #T_e57e2_row2_col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e57e2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e57e2_level0_col0\" class=\"col_heading level0 col0\" >Train Time</th>\n",
       "      <th id=\"T_e57e2_level0_col1\" class=\"col_heading level0 col1\" >Train Accuracy</th>\n",
       "      <th id=\"T_e57e2_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "      <th id=\"T_e57e2_level0_col3\" class=\"col_heading level0 col3\" >LogLoss</th>\n",
       "      <th id=\"T_e57e2_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_e57e2_level0_col5\" class=\"col_heading level0 col5\" >Recall</th>\n",
       "      <th id=\"T_e57e2_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_e57e2_level0_col7\" class=\"col_heading level0 col7\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e57e2_level0_row0\" class=\"row_heading level0 row0\" >DummyClassifier: most_frequent</th>\n",
       "      <td id=\"T_e57e2_row0_col0\" class=\"data row0 col0\" >0.09s</td>\n",
       "      <td id=\"T_e57e2_row0_col1\" class=\"data row0 col1\" >28.93%</td>\n",
       "      <td id=\"T_e57e2_row0_col2\" class=\"data row0 col2\" >28.93%</td>\n",
       "      <td id=\"T_e57e2_row0_col3\" class=\"data row0 col3\" >25.6175</td>\n",
       "      <td id=\"T_e57e2_row0_col4\" class=\"data row0 col4\" >8.37%</td>\n",
       "      <td id=\"T_e57e2_row0_col5\" class=\"data row0 col5\" >28.93%</td>\n",
       "      <td id=\"T_e57e2_row0_col6\" class=\"data row0 col6\" >12.98%</td>\n",
       "      <td id=\"T_e57e2_row0_col7\" class=\"data row0 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e57e2_level0_row1\" class=\"row_heading level0 row1\" >DummyClassifier: uniform</th>\n",
       "      <td id=\"T_e57e2_row1_col0\" class=\"data row1 col0\" >0.10s</td>\n",
       "      <td id=\"T_e57e2_row1_col1\" class=\"data row1 col1\" >2.21%</td>\n",
       "      <td id=\"T_e57e2_row1_col2\" class=\"data row1 col2\" >2.21%</td>\n",
       "      <td id=\"T_e57e2_row1_col3\" class=\"data row1 col3\" >3.8067</td>\n",
       "      <td id=\"T_e57e2_row1_col4\" class=\"data row1 col4\" >11.62%</td>\n",
       "      <td id=\"T_e57e2_row1_col5\" class=\"data row1 col5\" >2.21%</td>\n",
       "      <td id=\"T_e57e2_row1_col6\" class=\"data row1 col6\" >3.12%</td>\n",
       "      <td id=\"T_e57e2_row1_col7\" class=\"data row1 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e57e2_level0_row2\" class=\"row_heading level0 row2\" >DummyClassifier: stratified</th>\n",
       "      <td id=\"T_e57e2_row2_col0\" class=\"data row2 col0\" >0.09s</td>\n",
       "      <td id=\"T_e57e2_row2_col1\" class=\"data row2 col1\" >11.55%</td>\n",
       "      <td id=\"T_e57e2_row2_col2\" class=\"data row2 col2\" >11.44%</td>\n",
       "      <td id=\"T_e57e2_row2_col3\" class=\"data row2 col3\" >31.9203</td>\n",
       "      <td id=\"T_e57e2_row2_col4\" class=\"data row2 col4\" >11.46%</td>\n",
       "      <td id=\"T_e57e2_row2_col5\" class=\"data row2 col5\" >11.44%</td>\n",
       "      <td id=\"T_e57e2_row2_col6\" class=\"data row2 col6\" >11.45%</td>\n",
       "      <td id=\"T_e57e2_row2_col7\" class=\"data row2 col7\" >49.95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x130332050>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=data_utils.Config.TBL_HILITE_COLOR\n",
    "results_defaults_styled = results_defaults_df[report_cols].style.map(lambda val: f'background-color: {hilite}',\n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_defaults_styled = results_defaults_styled.set_table_styles({\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_defaults_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad55b07-8a6b-4291-b583-12862846b9f0",
   "metadata": {},
   "source": [
    "#### Default Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c66344-0d73-429e-85eb-205a9ecd5722",
   "metadata": {},
   "source": [
    "We will now explore the selected models with out-of-the-box default settings of their hyperparameters to get a baseline per model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "744a6a88-2c2b-422d-ab1e-5a4edaab9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default models\n",
    "models_default = {\n",
    "    'LogisticRegression (Default)': LogisticRegression(random_state=Config.RANDOM_STATE),\n",
    "    'KNeighborsClassifier (Default)': KNeighborsClassifier(),\n",
    "    'RandomForestClassifier (Default)': RandomForestClassifier(random_state=Config.RANDOM_STATE),\n",
    "    'XGBClassifier (Default)': XGBClassifier(random_state=Config.RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8eb69be-88f4-4363-9e49-9c8b34489f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (Default): Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (Default): Done: 2m 30.01s\n",
      "KNeighborsClassifier (Default): Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier (Default): Done: 10m 11.71s\n",
      "RandomForestClassifier (Default): Starting\n",
      "RandomForestClassifier (Default): Done: 10m 2.51s\n",
      "XGBClassifier (Default): Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier (Default): Done: 4m 54.55s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_default.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5dbde986-8ade-42db-9c5d-7afab3ccf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81c42370-9539-4502-8398-bba9f7536cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2b66f th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_2b66f th.col2 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_2b66f_row0_col2, #T_2b66f_row0_col3, #T_2b66f_row1_col2, #T_2b66f_row1_col3, #T_2b66f_row2_col2, #T_2b66f_row2_col3, #T_2b66f_row3_col2, #T_2b66f_row3_col3, #T_2b66f_row4_col2, #T_2b66f_row4_col3, #T_2b66f_row5_col2, #T_2b66f_row5_col3, #T_2b66f_row6_col2, #T_2b66f_row6_col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b66f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2b66f_level0_col0\" class=\"col_heading level0 col0\" >Train Time</th>\n",
       "      <th id=\"T_2b66f_level0_col1\" class=\"col_heading level0 col1\" >Train Accuracy</th>\n",
       "      <th id=\"T_2b66f_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "      <th id=\"T_2b66f_level0_col3\" class=\"col_heading level0 col3\" >LogLoss</th>\n",
       "      <th id=\"T_2b66f_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_2b66f_level0_col5\" class=\"col_heading level0 col5\" >Recall</th>\n",
       "      <th id=\"T_2b66f_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_2b66f_level0_col7\" class=\"col_heading level0 col7\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row0\" class=\"row_heading level0 row0\" >RandomForestClassifier (Default)</th>\n",
       "      <td id=\"T_2b66f_row0_col0\" class=\"data row0 col0\" >5m 35.47s</td>\n",
       "      <td id=\"T_2b66f_row0_col1\" class=\"data row0 col1\" >87.94%</td>\n",
       "      <td id=\"T_2b66f_row0_col2\" class=\"data row0 col2\" >33.97%</td>\n",
       "      <td id=\"T_2b66f_row0_col3\" class=\"data row0 col3\" >5.6816</td>\n",
       "      <td id=\"T_2b66f_row0_col4\" class=\"data row0 col4\" >28.66%</td>\n",
       "      <td id=\"T_2b66f_row0_col5\" class=\"data row0 col5\" >33.97%</td>\n",
       "      <td id=\"T_2b66f_row0_col6\" class=\"data row0 col6\" >29.36%</td>\n",
       "      <td id=\"T_2b66f_row0_col7\" class=\"data row0 col7\" >72.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row1\" class=\"row_heading level0 row1\" >XGBClassifier (Default)</th>\n",
       "      <td id=\"T_2b66f_row1_col0\" class=\"data row1 col0\" >3m 58.44s</td>\n",
       "      <td id=\"T_2b66f_row1_col1\" class=\"data row1 col1\" >35.92%</td>\n",
       "      <td id=\"T_2b66f_row1_col2\" class=\"data row1 col2\" >33.64%</td>\n",
       "      <td id=\"T_2b66f_row1_col3\" class=\"data row1 col3\" >2.3761</td>\n",
       "      <td id=\"T_2b66f_row1_col4\" class=\"data row1 col4\" >27.36%</td>\n",
       "      <td id=\"T_2b66f_row1_col5\" class=\"data row1 col5\" >33.64%</td>\n",
       "      <td id=\"T_2b66f_row1_col6\" class=\"data row1 col6\" >24.63%</td>\n",
       "      <td id=\"T_2b66f_row1_col7\" class=\"data row1 col7\" >74.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression (Default)</th>\n",
       "      <td id=\"T_2b66f_row2_col0\" class=\"data row2 col0\" >2m 25.31s</td>\n",
       "      <td id=\"T_2b66f_row2_col1\" class=\"data row2 col1\" >29.19%</td>\n",
       "      <td id=\"T_2b66f_row2_col2\" class=\"data row2 col2\" >29.19%</td>\n",
       "      <td id=\"T_2b66f_row2_col3\" class=\"data row2 col3\" >2.6363</td>\n",
       "      <td id=\"T_2b66f_row2_col4\" class=\"data row2 col4\" >13.94%</td>\n",
       "      <td id=\"T_2b66f_row2_col5\" class=\"data row2 col5\" >29.19%</td>\n",
       "      <td id=\"T_2b66f_row2_col6\" class=\"data row2 col6\" >14.65%</td>\n",
       "      <td id=\"T_2b66f_row2_col7\" class=\"data row2 col7\" >63.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row3\" class=\"row_heading level0 row3\" >DummyClassifier: most_frequent</th>\n",
       "      <td id=\"T_2b66f_row3_col0\" class=\"data row3 col0\" >0.09s</td>\n",
       "      <td id=\"T_2b66f_row3_col1\" class=\"data row3 col1\" >28.93%</td>\n",
       "      <td id=\"T_2b66f_row3_col2\" class=\"data row3 col2\" >28.93%</td>\n",
       "      <td id=\"T_2b66f_row3_col3\" class=\"data row3 col3\" >25.6175</td>\n",
       "      <td id=\"T_2b66f_row3_col4\" class=\"data row3 col4\" >8.37%</td>\n",
       "      <td id=\"T_2b66f_row3_col5\" class=\"data row3 col5\" >28.93%</td>\n",
       "      <td id=\"T_2b66f_row3_col6\" class=\"data row3 col6\" >12.98%</td>\n",
       "      <td id=\"T_2b66f_row3_col7\" class=\"data row3 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row4\" class=\"row_heading level0 row4\" >KNeighborsClassifier (Default)</th>\n",
       "      <td id=\"T_2b66f_row4_col0\" class=\"data row4 col0\" >1.93s</td>\n",
       "      <td id=\"T_2b66f_row4_col1\" class=\"data row4 col1\" >44.13%</td>\n",
       "      <td id=\"T_2b66f_row4_col2\" class=\"data row4 col2\" >24.83%</td>\n",
       "      <td id=\"T_2b66f_row4_col3\" class=\"data row4 col3\" >18.7904</td>\n",
       "      <td id=\"T_2b66f_row4_col4\" class=\"data row4 col4\" >19.91%</td>\n",
       "      <td id=\"T_2b66f_row4_col5\" class=\"data row4 col5\" >24.83%</td>\n",
       "      <td id=\"T_2b66f_row4_col6\" class=\"data row4 col6\" >20.96%</td>\n",
       "      <td id=\"T_2b66f_row4_col7\" class=\"data row4 col7\" >61.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row5\" class=\"row_heading level0 row5\" >DummyClassifier: uniform</th>\n",
       "      <td id=\"T_2b66f_row5_col0\" class=\"data row5 col0\" >0.10s</td>\n",
       "      <td id=\"T_2b66f_row5_col1\" class=\"data row5 col1\" >2.21%</td>\n",
       "      <td id=\"T_2b66f_row5_col2\" class=\"data row5 col2\" >2.21%</td>\n",
       "      <td id=\"T_2b66f_row5_col3\" class=\"data row5 col3\" >3.8067</td>\n",
       "      <td id=\"T_2b66f_row5_col4\" class=\"data row5 col4\" >11.62%</td>\n",
       "      <td id=\"T_2b66f_row5_col5\" class=\"data row5 col5\" >2.21%</td>\n",
       "      <td id=\"T_2b66f_row5_col6\" class=\"data row5 col6\" >3.12%</td>\n",
       "      <td id=\"T_2b66f_row5_col7\" class=\"data row5 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b66f_level0_row6\" class=\"row_heading level0 row6\" >DummyClassifier: stratified</th>\n",
       "      <td id=\"T_2b66f_row6_col0\" class=\"data row6 col0\" >0.09s</td>\n",
       "      <td id=\"T_2b66f_row6_col1\" class=\"data row6 col1\" >11.55%</td>\n",
       "      <td id=\"T_2b66f_row6_col2\" class=\"data row6 col2\" >11.44%</td>\n",
       "      <td id=\"T_2b66f_row6_col3\" class=\"data row6 col3\" >31.9203</td>\n",
       "      <td id=\"T_2b66f_row6_col4\" class=\"data row6 col4\" >11.46%</td>\n",
       "      <td id=\"T_2b66f_row6_col5\" class=\"data row6 col5\" >11.44%</td>\n",
       "      <td id=\"T_2b66f_row6_col6\" class=\"data row6 col6\" >11.45%</td>\n",
       "      <td id=\"T_2b66f_row6_col7\" class=\"data row6 col7\" >49.95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ad3d6d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=data_utils.Config.TBL_HILITE_COLOR\n",
    "results_defaults_styled = results_defaults_df[report_cols].style.map(lambda val: f'background-color: {hilite}',\n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_defaults_styled = results_defaults_styled.set_table_styles({\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_defaults_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec75288c-653c-44a3-b465-cac3f869b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_defaults_styled, data_utils.Config.IMAGE_DIR / 'table_models_defaults.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3c961-58d1-4262-9885-72217bb84eda",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c673584b-bc59-43da-908c-335324579987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_tuned = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols_tuned = ['params', 'Train Time', \n",
    "                     'Train Accuracy', 'Test Accuracy', 'LogLoss',\n",
    "                     'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1dd0954-4948-4d9f-ad5c-6b37e1a75cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default models\n",
    "models_tuned = {\n",
    "    'LogisticRegression': LogisticRegression(penalty='l1', solver='saga', max_iter=1000, \n",
    "                                             verbose=1, n_jobs=3, random_state=Config.RANDOM_STATE),\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=n_estimators, max_depth=15,\n",
    "                                                     min_samples_leaf=5, min_samples_split=25, \n",
    "                                                     random_state=Config.RANDOM_STATE, \n",
    "                                                     verbose=1, n_jobs=2),\n",
    "    'XGBClassifier': XGBClassifier(n_estimators=n_estimators, objective=\"multi:softprob\", \n",
    "                                   n_jobs=2, random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bc344af-5cea-482f-a14b-fe3f0bbb7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 30 epochs took 124 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Done: 2m 27.10s\n",
      "RandomForestClassifier: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    6.0s finished\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Done: 5m 50.11s\n",
      "XGBClassifier: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier: Done: 14m 49.13s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_tuned.items():\n",
    "    results_tuned[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4472a293-5e12-410f-97c3-42e4d1193b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_tuned_df = pd.DataFrame(results_tuned).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14d4a2a2-9414-4556-906f-223f90ade436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de705 td.col0 {\n",
       "  max-width: 300px;\n",
       "  white-space: normal;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_de705 th.col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_de705 th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_de705_row0_col3, #T_de705_row0_col4, #T_de705_row1_col3, #T_de705_row1_col4, #T_de705_row2_col3, #T_de705_row2_col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de705\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de705_level0_col0\" class=\"col_heading level0 col0\" >params</th>\n",
       "      <th id=\"T_de705_level0_col1\" class=\"col_heading level0 col1\" >Train Time</th>\n",
       "      <th id=\"T_de705_level0_col2\" class=\"col_heading level0 col2\" >Train Accuracy</th>\n",
       "      <th id=\"T_de705_level0_col3\" class=\"col_heading level0 col3\" >Test Accuracy</th>\n",
       "      <th id=\"T_de705_level0_col4\" class=\"col_heading level0 col4\" >LogLoss</th>\n",
       "      <th id=\"T_de705_level0_col5\" class=\"col_heading level0 col5\" >Precision</th>\n",
       "      <th id=\"T_de705_level0_col6\" class=\"col_heading level0 col6\" >Recall</th>\n",
       "      <th id=\"T_de705_level0_col7\" class=\"col_heading level0 col7\" >F1</th>\n",
       "      <th id=\"T_de705_level0_col8\" class=\"col_heading level0 col8\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de705_level0_row0\" class=\"row_heading level0 row0\" >XGBClassifier</th>\n",
       "      <td id=\"T_de705_row0_col0\" class=\"data row0 col0\" >{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': 2, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}</td>\n",
       "      <td id=\"T_de705_row0_col1\" class=\"data row0 col1\" >10m 36.97s</td>\n",
       "      <td id=\"T_de705_row0_col2\" class=\"data row0 col2\" >35.92%</td>\n",
       "      <td id=\"T_de705_row0_col3\" class=\"data row0 col3\" >33.64%</td>\n",
       "      <td id=\"T_de705_row0_col4\" class=\"data row0 col4\" >2.3761</td>\n",
       "      <td id=\"T_de705_row0_col5\" class=\"data row0 col5\" >27.36%</td>\n",
       "      <td id=\"T_de705_row0_col6\" class=\"data row0 col6\" >33.64%</td>\n",
       "      <td id=\"T_de705_row0_col7\" class=\"data row0 col7\" >24.63%</td>\n",
       "      <td id=\"T_de705_row0_col8\" class=\"data row0 col8\" >74.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de705_level0_row1\" class=\"row_heading level0 row1\" >RandomForestClassifier</th>\n",
       "      <td id=\"T_de705_row1_col0\" class=\"data row1 col0\" >{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': 2, 'oob_score': False, 'random_state': 42, 'verbose': 1, 'warm_start': False}</td>\n",
       "      <td id=\"T_de705_row1_col1\" class=\"data row1 col1\" >4m 44.66s</td>\n",
       "      <td id=\"T_de705_row1_col2\" class=\"data row1 col2\" >35.67%</td>\n",
       "      <td id=\"T_de705_row1_col3\" class=\"data row1 col3\" >33.05%</td>\n",
       "      <td id=\"T_de705_row1_col4\" class=\"data row1 col4\" >2.4068</td>\n",
       "      <td id=\"T_de705_row1_col5\" class=\"data row1 col5\" >28.66%</td>\n",
       "      <td id=\"T_de705_row1_col6\" class=\"data row1 col6\" >33.05%</td>\n",
       "      <td id=\"T_de705_row1_col7\" class=\"data row1 col7\" >21.77%</td>\n",
       "      <td id=\"T_de705_row1_col8\" class=\"data row1 col8\" >74.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de705_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression</th>\n",
       "      <td id=\"T_de705_row2_col0\" class=\"data row2 col0\" >{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': 3, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga', 'tol': 0.0001, 'verbose': 1, 'warm_start': False}</td>\n",
       "      <td id=\"T_de705_row2_col1\" class=\"data row2 col1\" >2m 3.84s</td>\n",
       "      <td id=\"T_de705_row2_col2\" class=\"data row2 col2\" >29.19%</td>\n",
       "      <td id=\"T_de705_row2_col3\" class=\"data row2 col3\" >29.20%</td>\n",
       "      <td id=\"T_de705_row2_col4\" class=\"data row2 col4\" >2.6362</td>\n",
       "      <td id=\"T_de705_row2_col5\" class=\"data row2 col5\" >14.15%</td>\n",
       "      <td id=\"T_de705_row2_col6\" class=\"data row2 col6\" >29.20%</td>\n",
       "      <td id=\"T_de705_row2_col7\" class=\"data row2 col7\" >14.66%</td>\n",
       "      <td id=\"T_de705_row2_col8\" class=\"data row2 col8\" >63.23%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ad72050>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=data_utils.Config.TBL_HILITE_COLOR\n",
    "results_tuned_styled = results_tuned_df[report_cols_tuned].style.map(lambda val: f'background-color: {hilite}', \n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_tuned_styled = results_tuned_styled.set_table_styles({\n",
    "    'params': [{'selector': 'td', 'props': [('max-width', '300px'), \n",
    "                                  ('white-space', 'normal'), \n",
    "                                  ('word-wrap', 'break-word')]}],\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_tuned_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdfbdc72-870d-40e0-b354-32f7848730cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_tuned_styled, data_utils.Config.IMAGE_DIR / 'table_models_tuned.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24849f0-e427-4247-9ccd-e3f9cab73961",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee9584-8737-4017-ad06-e1eb3e515972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

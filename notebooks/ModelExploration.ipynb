{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800f300e-1c9d-4f8e-9bce-aa31778a3bbc",
   "metadata": {},
   "source": [
    "# Capstone: Exploratory Prediction Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01487d5-79f9-4b8e-8ee4-e8f176052d7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports & Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664ba4c-d619-459d-9a39-12d9fc1332c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b05fd2b-87c4-4db0-9bb5-1ae0748656bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Import utilities\n",
    "# import pathlib\n",
    "import time\n",
    "\n",
    "# Export dataFrame's as images\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# import project utils\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import data_utils\n",
    "from data_utils import Config\n",
    "\n",
    "import graph_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, log_loss\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4214fe9c-8a7e-46d6-a79e-48fe4150289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607625a-2eb2-441f-860b-8c2c00a36c9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c6b335-5290-483d-8aa6-5b7f9b7b5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_secs_to_msg(lapse_time_secs, mins_label='m', secs_label='s'):\n",
    "    if lapse_time_secs <= 60:\n",
    "        return f'{lapse_time_secs%60:.2f}{secs_label}'\n",
    "    else:\n",
    "        return f'{lapse_time_secs//60:,.0f}{mins_label} {lapse_time_secs%60:.2f}{secs_label}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adee9584-8737-4017-ad06-e1eb3e515972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_optimizer_status_cv(optimizer_results):\n",
    "    \"\"\"\n",
    "    Summarizes optimizer results for each iteration so we can see what params are impactful\n",
    "\n",
    "    :params optimizer_results: Optimizer data passed in the callback\n",
    "    \"\"\"\n",
    "\n",
    "    iter_num = len(optimizer_results[\"x_iters\"])\n",
    "    # print(f'... Iteration #{iter_num} Best(score: {optimizer_results[\"func_vals\"][iter_num-1]:,.4f}, best_params: {optimizer_results[\"x\"]})')\n",
    "    print('... Iteration #{} Best(score: {:,.4f}, best_params: {})'\n",
    "          .format(iter_num, optimizer_results[\"func_vals\"][iter_num-1], optimizer_results[\"x\"]))\n",
    "    # print(f'... opt_r={optimizer_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d907e6-792a-4c8b-bd67-a4818a4a1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_row(name, model, Xtr, Xte, ytr, yte, optimizer=None):\n",
    "    \"\"\"\n",
    "    Given the model and training/test sets, builds a row of metrics for reporting the results\n",
    "\n",
    "    :param name: Name/Description of model\n",
    "    :param model: Fully constructed model instance - will call fit() and predict() to get metrics\n",
    "    :param Xtr: X_train - scale before calling\n",
    "    :param Xte: X_test - scale before calling\n",
    "    :param ytr: Y_train set\n",
    "    :param yteL: Y_test set\n",
    "    :param optimizer: If using CV for optimization, pass in the optimizer here\n",
    "    \"\"\"\n",
    "\n",
    "    if optimizer is None:\n",
    "        use_best = False\n",
    "    else:\n",
    "        use_best = True\n",
    "        # clf = optimizer\n",
    "        \n",
    "    print(f'{name}: Starting (use_best={use_best})', flush=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train the model\n",
    "    clf = None\n",
    "    if (use_best):\n",
    "        clf = optimizer.fit(Xtr, ytr, callback=log_optimizer_status_cv)\n",
    "    else:\n",
    "        clf = model.fit(Xtr, ytr)\n",
    "        \n",
    "    # Save fit time\n",
    "    fit_time = time.time() - start_time\n",
    "    logging.debug(f'{name}: Fitted: {fit_time} secs')\n",
    "\n",
    "    # if we're tuning then use best_estimator\n",
    "    if use_best:\n",
    "        clf = optimizer.best_estimator_\n",
    "        logging.debug(f'{name}: Best Model={clf}')\n",
    "        logging.debug(f'{name}: Best Params={optimizer.best_params_}')\n",
    "\n",
    "    # get the predictions / probabilities\n",
    "    y_preds = clf.predict(Xte)\n",
    "    y_probs_full = clf.predict_proba(Xte)\n",
    "    y_probs = y_probs_full[:, 1]\n",
    "\n",
    "    logging.debug(f'{name}: Got preds/probs')\n",
    "\n",
    "    cm = confusion_matrix(yte, y_preds)\n",
    "    logging.debug(f'{name}: cm.shape: {cm.shape}')\n",
    "\n",
    "    # Get metrics\n",
    "    row = {\n",
    "        'Train Time': time_secs_to_msg(fit_time),\n",
    "        'Train Accuracy': f'{clf.score(Xtr, ytr)*100:.2f}%',\n",
    "        'Test Accuracy': f'{clf.score(Xte, yte)*100:.2f}%',\n",
    "        'Precision': f'{precision_score(yte, y_preds, average=\"weighted\")*100:.2f}%',  # for multi-class with imbalance\n",
    "        'Recall': f'{recall_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'F1': f'{f1_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'AUC': f'{roc_auc_score(yte, y_probs_full, average=\"weighted\", multi_class=\"ovr\")*100:.2f}%',    # faster with imbalanced multi-class cases\n",
    "        'LogLoss': f'{log_loss(yte, y_probs_full, labels=np.unique(yte)):.4f}',\n",
    "        'preds': y_preds,\n",
    "        'probs': y_probs,\n",
    "        'cm': cm,\n",
    "        'params': clf.get_params(),\n",
    "        'best_params': None,\n",
    "        'best_model': clf,\n",
    "    }\n",
    "    if use_best:\n",
    "        row.update({'best_params': dict(optimizer.best_params_)})\n",
    "        \n",
    "    logging.debug(f'{name}: Got metrics')\n",
    "    \n",
    "    print(f'{name}: Done: {time_secs_to_msg(time.time()-start_time)}')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814d6a5-3ae8-43f1-b00f-5b22986f3267",
   "metadata": {},
   "source": [
    "## The Data: San Francisco Police Department Incident Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd64605-3a3b-480b-be39-711b70beb7cc",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3250ab5b-8240-4f47-9438-aecea04d69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sample file: ../data/incidents_clean_10_pct.csv\n"
     ]
    }
   ],
   "source": [
    "# Which dataset to work from? Select sample size percentage\n",
    "\n",
    "sample_file = data_utils.select_sample_csv_file(pct=10)\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=100)\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=75)\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=50)\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=25)\n",
    "\n",
    "print(f'Selected sample file: {sample_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f7eb17-698f-4eba-aebc-c2893f443e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ../data/incidents_clean_10_pct.csv ... Done: 89,458 rows, 37 columns\n",
      "... Converting datetime to timeseries ... Done\n",
      "... Setting index to datetime ... Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "current_raw_df, current_clean_df = data_utils.get_clean_data_from_csv(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49438aea-557f-49a0-9caf-2a230ea378f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing ... \n",
      "... Dropping unwanted columns ... \n",
      "... preprocess_drop_cols: Column Unnamed: 0 dropped\n",
      "... preprocess_drop_cols: Column esncag_-_boundary_file dropped\n",
      "... preprocess_drop_cols: Column central_market/tenderloin_boundary_polygon_-_updated dropped\n",
      "... preprocess_drop_cols: Column civic_center_harm_reduction_project_boundary dropped\n",
      "... preprocess_drop_cols: Column hsoc_zones_as_of_2018-06-05 dropped\n",
      "... preprocess_drop_cols: Column invest_in_neighborhoods_(iin)_areas dropped\n",
      "... preprocess_drop_cols: Column report_type_code dropped\n",
      "... preprocess_drop_cols: Column report_type_description dropped\n",
      "... preprocess_drop_cols: Column filed_online dropped\n",
      "... preprocess_drop_cols: Column intersection dropped\n",
      "... preprocess_drop_cols: Column cnn dropped\n",
      "... preprocess_drop_cols: Column point dropped\n",
      "... preprocess_drop_cols: Column supervisor_district dropped\n",
      "... preprocess_drop_cols: Column supervisor_district_2012 dropped\n",
      "... preprocess_drop_cols: Column current_supervisor_districts dropped\n",
      "... preprocess_drop_cols: Column incident_datetime dropped\n",
      "... preprocess_drop_cols: Column report_datetime dropped\n",
      "... preprocess_drop_cols: Column incident_id dropped\n",
      "... preprocess_drop_cols: Column incident_code dropped\n",
      "... preprocess_drop_cols: Column row_id dropped\n",
      "... preprocess_drop_cols: Column incident_number dropped\n",
      "... preprocess_drop_cols: Column cad_number dropped\n",
      "... preprocess_drop_cols: Column incident_subcategory dropped\n",
      "... preprocess_drop_cols: Column incident_description dropped\n",
      "... preprocess_drop_cols: Column current_police_districts dropped\n",
      "... preprocess_drop_cols: Column neighborhoods dropped\n",
      "... Done\n",
      "... Removing resolution types: \"Unfounded\", \"Exceptional Adult\" ... \n",
      "... Removing police_district types: \"Out of SF\" ... \n",
      "... Renaming column: \"analysis_neighborhood\" -> \"neighborhood\" ... \n",
      "... Renaming columns: Dropping \"incident_*\" from column names ... \n",
      "... Removing rows with nulls (dropna) ... \n",
      "... Done\n",
      "Done: Start: (89458, 36), End: (82888, 10) -> Rows removed: 6,570 rows (7.34%)\n"
     ]
    }
   ],
   "source": [
    "data = data_utils.preprocess_data(current_raw_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796600d8-4dc4-4367-8bdd-48602641b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data artifacts (in-place) ... \n",
      "... Category column:\n",
      "    ...\"Human Trafficking*\"\n",
      "    ...\"Motor Vehicle Theft\"\n",
      "    ...\"Weapons Offence\"\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Fix data value artifacts that were discovered during EDA\n",
    "data = data_utils.fix_data_artifacts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0593a1a6-d608-4168-ab60-698d8e3a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             82888 non-null  object \n",
      " 1   time             82888 non-null  object \n",
      " 2   year             82888 non-null  int64  \n",
      " 3   day_of_week      82888 non-null  object \n",
      " 4   category         82888 non-null  object \n",
      " 5   resolution       82888 non-null  object \n",
      " 6   police_district  82888 non-null  object \n",
      " 7   neighborhood     82888 non-null  object \n",
      " 8   latitude         82888 non-null  float64\n",
      " 9   longitude        82888 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b6f7-2f63-409e-8a77-d95a82a599b2",
   "metadata": {},
   "source": [
    "## Summary of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62469-b0fa-405b-ae5e-9cf32c9994a4",
   "metadata": {},
   "source": [
    "After cleaning the data and performing basic EDA, we have established the following:\n",
    "\n",
    "1. Target variable `category`\n",
    "   * Evenly spread across time\n",
    "   * Incidence of crimes is extremely skewed/unbalanced by category. Larceny (29.02%) by far outweighing the other top-10 categories with each being in the single digits\n",
    "3. Features impacting `category`\n",
    "   * Affected by incident time and date components: date, time, day of week, month, year, etc\n",
    "   * Affected by police disctrict\n",
    "   * Affect by latitude and logitude (TODO: need visualization)\n",
    "4. We artificially removed nulls (TODO: will come back to impute data later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4580fda-167c-419e-94a4-466d884169d8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3693b1c-6a4c-4480-99c3-1afb183a1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>category</th>\n",
       "      <th>resolution</th>\n",
       "      <th>police_district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <td>2024/08/01</td>\n",
       "      <td>08:01</td>\n",
       "      <td>2024</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Other Miscellaneous</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Mission</td>\n",
       "      <td>Mission</td>\n",
       "      <td>37.768272</td>\n",
       "      <td>-122.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>23:30</td>\n",
       "      <td>2021</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Northern</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>-122.432467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date   time  year day_of_week             category  \\\n",
       "datetime                                                                        \n",
       "2024-08-01 08:01:00  2024/08/01  08:01  2024    Thursday  Other Miscellaneous   \n",
       "2021-11-25 23:30:00  2021/11/25  23:30  2021    Thursday             Burglary   \n",
       "\n",
       "                         resolution police_district    neighborhood  \\\n",
       "datetime                                                              \n",
       "2024-08-01 08:01:00  Open or Active         Mission         Mission   \n",
       "2021-11-25 23:30:00  Open or Active        Northern  Haight Ashbury   \n",
       "\n",
       "                      latitude   longitude  \n",
       "datetime                                    \n",
       "2024-08-01 08:01:00  37.768272 -122.419983  \n",
       "2021-11-25 23:30:00  37.773757 -122.432467  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c52ff3-baa7-47e8-95e7-6b65ffd9424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             82888 non-null  object \n",
      " 1   time             82888 non-null  object \n",
      " 2   year             82888 non-null  int64  \n",
      " 3   day_of_week      82888 non-null  object \n",
      " 4   category         82888 non-null  object \n",
      " 5   resolution       82888 non-null  object \n",
      " 6   police_district  82888 non-null  object \n",
      " 7   neighborhood     82888 non-null  object \n",
      " 8   latitude         82888 non-null  float64\n",
      " 9   longitude        82888 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93db1b-4718-4bac-8a22-8aff944c3c64",
   "metadata": {},
   "source": [
    "### Encoding: Time-based columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6939cb5-85c3-4f3e-92f8-23347859bded",
   "metadata": {},
   "source": [
    "Let's unpack the date and time into their components that are still missing so there is less to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e80e1ca0-445e-4251-8672-a70c5ef40597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour'] = data.index.map(lambda x: x.hour)\n",
    "data['minute'] = data.index.map(lambda x: x.minute)\n",
    "data['day'] = data.index.map(lambda x: x.day)\n",
    "data['month'] = data.index.map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834113f-4129-4c28-9ca6-f2f5051b7b1e",
   "metadata": {},
   "source": [
    "Now let's encode day_of_week to numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba3c50f-bc77-4491-b663-4ea286c5774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dow = LabelEncoder()\n",
    "enc_dow.fit(data.day_of_week.unique())\n",
    "data['dow'] = enc_dow.transform(data.day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb03a71-9c9e-4bca-af32-b35f05db2e1e",
   "metadata": {},
   "source": [
    "Let's mark the redundant columns to be dropped after feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ce4c19a-dbf1-49c6-8fc5-c91a4e72aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols = ['date', 'time', 'day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474b64-0486-4de0-9fe3-85dd1df87559",
   "metadata": {},
   "source": [
    "### Encoding: Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fb531-2e4c-4f36-bf09-00bc9ca6c0e3",
   "metadata": {},
   "source": [
    "We will also drop the resolution column since it doesn't impact crime prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d130971c-9f96-40c2-a973-bb5ada873544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolution\n",
       "Open or Active          66265\n",
       "Cite or Arrest Adult    16623\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.resolution.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b60a7a-4290-42c5-bdcc-12436361160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols.append('resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a27a2a-a4e1-46e6-aaaa-6462a88ef904",
   "metadata": {},
   "source": [
    "### Encoding: Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1887058d-290d-4de7-be1a-ad4790edc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cat = LabelEncoder()\n",
    "enc_cat.fit(data.category.unique())\n",
    "data.category = enc_cat.transform(data.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4357e80-34aa-426c-8360-15da700f3136",
   "metadata": {},
   "source": [
    "### Encoding: Police District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b918e7f-285b-4cd6-9960-7fe80b848c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pd = LabelEncoder()\n",
    "enc_pd.fit(data.police_district.unique())\n",
    "data['pd'] = enc_pd.transform(data.police_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b758e-6f91-45af-b590-f526a8d84033",
   "metadata": {},
   "source": [
    "### Encoding: Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82fb1300-2f74-4930-94ab-a5b161e4b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hood = LabelEncoder()\n",
    "enc_hood.fit(data.neighborhood.unique())\n",
    "data.neighborhood = enc_hood.transform(data.neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844c0b5-1967-46f3-b316-5f8e2a1e4e74",
   "metadata": {},
   "source": [
    "### Dropping Redundant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40759752-bd7b-40ee-9503-2778c2594c9f",
   "metadata": {},
   "source": [
    "We can now drop the redundant encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db644549-7780-4117-be95-207dde3eb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping encoded columns: ['date', 'time', 'day_of_week', 'resolution', 'police_district']\n"
     ]
    }
   ],
   "source": [
    "drop_encoded_cols.append('police_district')\n",
    "\n",
    "print(f'Dropping encoded columns: {drop_encoded_cols}')\n",
    "data.drop(columns=drop_encoded_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de363da7-290a-4a98-bee6-2760db2cb526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>pd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <td>2024</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>37.768272</td>\n",
       "      <td>-122.419983</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>-122.432467</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  category  neighborhood   latitude   longitude  \\\n",
       "datetime                                                                   \n",
       "2024-08-01 08:01:00  2024        26            18  37.768272 -122.419983   \n",
       "2021-11-25 23:30:00  2021         2             8  37.773757 -122.432467   \n",
       "\n",
       "                     hour  minute  day  month  dow  pd  \n",
       "datetime                                                \n",
       "2024-08-01 08:01:00     8       1    1      8    4   3  \n",
       "2021-11-25 23:30:00    23      30   25     11    4   4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a45dd9e-7aa0-43c1-9d94-40d6287cb845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   year          82888 non-null  int64  \n",
      " 1   category      82888 non-null  int64  \n",
      " 2   neighborhood  82888 non-null  int64  \n",
      " 3   latitude      82888 non-null  float64\n",
      " 4   longitude     82888 non-null  float64\n",
      " 5   hour          82888 non-null  int64  \n",
      " 6   minute        82888 non-null  int64  \n",
      " 7   day           82888 non-null  int64  \n",
      " 8   month         82888 non-null  int64  \n",
      " 9   dow           82888 non-null  int64  \n",
      " 10  pd            82888 non-null  int64  \n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45a88c26-037c-4606-97fd-d4e1f866516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('../data/incidents_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7ab2c-d5a3-4d2a-b158-87ea45debe21",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d496dcd-171a-4d49-8807-11ffafa4b233",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac470dae-d362-45d4-911f-5906ce1e271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('category', axis='columns')\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9df7a80e-6033-412d-a282-ffa985f48904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode the features and drop the first value to reduce multicollinearity\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "140d725c-be87-47fd-b60d-6bee9e666ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project-wide random_state: 42\n"
     ]
    }
   ],
   "source": [
    "# Consistent random_state for the project\n",
    "print(f'Project-wide random_state: {Config.RANDOM_STATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f71f3ab-33fa-4ea3-bade-efc053e13870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=Config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1966aa94-1593-4fd3-a9af-f4501f0fa543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER TRAIN_TEST_SPLIT: Data(82888, 11), X_train(66310, 10), X_test(16578, 10), y_train(66310,), y_test(16578,)\n"
     ]
    }
   ],
   "source": [
    "print('AFTER TRAIN_TEST_SPLIT: Data{}, X_train{}, X_test{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a01d3fc6-d194-43b3-89eb-aa639586aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>datetime</th>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <th>2018-06-20 21:00:00</th>\n",
       "      <th>2022-07-06 12:41:00</th>\n",
       "      <th>2021-02-27 23:02:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2024.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>37.768272</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>37.723642</td>\n",
       "      <td>37.777457</td>\n",
       "      <td>37.770063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-122.419983</td>\n",
       "      <td>-122.432467</td>\n",
       "      <td>-122.461251</td>\n",
       "      <td>-122.413158</td>\n",
       "      <td>-122.403878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "datetime      2024-08-01 08:01:00  2021-11-25 23:30:00  2018-06-20 21:00:00  \\\n",
       "year                  2024.000000          2021.000000          2018.000000   \n",
       "neighborhood            18.000000             8.000000            23.000000   \n",
       "latitude                37.768272            37.773757            37.723642   \n",
       "longitude             -122.419983          -122.432467          -122.461251   \n",
       "hour                     8.000000            23.000000            21.000000   \n",
       "minute                   1.000000            30.000000             0.000000   \n",
       "day                      1.000000            25.000000            20.000000   \n",
       "month                    8.000000            11.000000             6.000000   \n",
       "dow                      4.000000             4.000000             6.000000   \n",
       "pd                       3.000000             4.000000             8.000000   \n",
       "\n",
       "datetime      2022-07-06 12:41:00  2021-02-27 23:02:00  \n",
       "year                  2022.000000          2021.000000  \n",
       "neighborhood            33.000000            19.000000  \n",
       "latitude                37.777457            37.770063  \n",
       "longitude             -122.413158          -122.403878  \n",
       "hour                    12.000000            23.000000  \n",
       "minute                  41.000000             2.000000  \n",
       "day                      6.000000            27.000000  \n",
       "month                    7.000000             2.000000  \n",
       "dow                      6.000000             2.000000  \n",
       "pd                       9.000000             7.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot-check feature encoding\n",
    "X.T.iloc[:, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ffce7-ac24-4443-a5df-81a0449852c6",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6ed9a74-008a-4c0f-b2af-76e5f0e54793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER SCALING: Data(82888, 11), X_train_scaled(66310, 10), X_test_scaled(16578, 10), y_train(66310,), y_test(16578,)\n"
     ]
    }
   ],
   "source": [
    "# Scale the data - we'll use StandardScaler for the baseline model\n",
    "logging.debug('Scaling data')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('AFTER SCALING: Data{}, X_train_scaled{}, X_test_scaled{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df8b27-6969-4b14-b3e0-f4e351df67d0",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a3fbc-b034-4ced-a667-57713c0453a4",
   "metadata": {},
   "source": [
    "The task of classifying the incident types based on a set of historical attrirbutes (features) and predicting on similar attributes is a **multiclass classification** problem. We will now experiment on some ML models that are generally used for similar problems to see what would be the best choice for us.\n",
    "\n",
    "We will evaluate the following models:\n",
    "\n",
    "* Simple classification models\n",
    "  * `DummyClassifier` to get a baseline for our project\n",
    "  * `LogisticRegression` with L1 Regularization\n",
    "* Multiclass classifiers\n",
    "  * `KNeighborsClassifier`\n",
    "* Ensemble methods: Since our dataset has high variability with a lot of numerical and cagtegorical features with a range of mean and variance, we plan to employ ensemble methods and tune them for best results\n",
    "  * `RandomForestClassifier`\n",
    "  * `XGBClassifier`: We considered `XGLite` but selected XGBoost as it provides better model explainability features like SHAP values, which we expect to be able to use in explaining our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e74d3-390d-4b30-acc2-d685aa461d76",
   "metadata": {},
   "source": [
    "We will now evaluate different models for predicting the Crime Category from our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fb217f2-ba53-4f9a-9fdf-c79a3deefe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'neighborhood', 'latitude', 'longitude', 'hour', 'minute',\n",
       "       'day', 'month', 'dow', 'pd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d149f8-5cf7-4455-9d03-e4018d377dd3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98634325-3d11-4c84-af0b-1cf89d0b122a",
   "metadata": {},
   "source": [
    "In this project, we are predicting or classifyig across 49 crime categories. We will use two evaluation metrics to compare our models:\n",
    "\n",
    "1. **Accuracy**: Measures the proportion of correct predictions over all predictions made. The accuracy benchmark is 1/49 or 2.04% given our crime categories\n",
    "2. **Log_Loss**: Measures the accuracy of a classifier by penalizing false classifications. It does this by taking the negative logarithm of the predicted probability for the true class. The goal is to minimize this loss, meaning that higher probabilities are assigned to the correct classes. Log loss is a powerful way to evaluate not just if the model is making the right predictions, but how confident it is in those predictions. A lower log loss indicates a model that is both accurate and confident.\n",
    "   * TODO: Benchmark???\n",
    "\n",
    "While accuracy provides a simple measure of correctness, log-loss offers a more nuanced view by considering how confident those predictions are. A model that predicts with 51% confidence for the correct class will have the same accuracy as one that predicts with 99% confidence, but their log loss will be very different. The 99%-confident model will have a much lower log loss.\n",
    "\n",
    "We'll use them together for a comprehensive evaluation and to learn more about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b0add-d301-47ef-afaf-781d93e3baba",
   "metadata": {},
   "source": [
    "The `build_results_row` utility function will be used to standardize the recording and reporting of our model exploration: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc07dee-bc84-47e9-9534-8cb45ba5895c",
   "metadata": {},
   "source": [
    "### Establishing a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437c17b-eece-4bc1-ae29-ed0f023056e3",
   "metadata": {},
   "source": [
    "#### DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443338d-fa9b-4c0c-8bd1-e831c3244043",
   "metadata": {},
   "source": [
    "We will use the Scikit-Learn DummyClassifier method to get a baseline for our predictions using the different strategies provided by the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5389318-135b-483b-a8a8-7cefd2223b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_defaults = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols = ['Train Time', \n",
    "               'Train Accuracy', 'Test Accuracy', 'LogLoss',\n",
    "               'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c554832-05bd-48c1-b3e3-6ab9a0e8ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DummyClassifier models we want to test\n",
    "models_dummy = {\n",
    "    'DummyClassifier: uniform': DummyClassifier(strategy='uniform', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: most_frequent': DummyClassifier(strategy='most_frequent', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: stratified': DummyClassifier(strategy='stratified', random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7cb9c0f-d499-40b1-bf03-da7978cf2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: uniform: Starting (use_best=False)\n",
      "DummyClassifier: uniform: Done: 0.21s\n",
      "DummyClassifier: most_frequent: Starting (use_best=False)\n",
      "DummyClassifier: most_frequent: Done: 0.17s\n",
      "DummyClassifier: stratified: Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: stratified: Done: 0.42s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_dummy.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aefff5-68d8-4f56-9c4e-932a17b16c7f",
   "metadata": {},
   "source": [
    "The warning above is from the precision calculation within scikit-learn, and highlights that some labels have no predicted samples, which results in precision being undefined for those labels. We can ignore the warning since we're using accuracy as our key evaluation metric. We could use `prescion_score(zero_division=0)` to suppress the warning, but we'll ignore it instead to ensure we're aware of the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e04a9d6-78c2-44c0-be2c-3070b772558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "865380fa-be16-41bf-b432-605606bbfa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a40d2 th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_a40d2 th.col2 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_a40d2_row0_col2, #T_a40d2_row0_col3, #T_a40d2_row1_col2, #T_a40d2_row1_col3, #T_a40d2_row2_col2, #T_a40d2_row2_col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a40d2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a40d2_level0_col0\" class=\"col_heading level0 col0\" >Train Time</th>\n",
       "      <th id=\"T_a40d2_level0_col1\" class=\"col_heading level0 col1\" >Train Accuracy</th>\n",
       "      <th id=\"T_a40d2_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "      <th id=\"T_a40d2_level0_col3\" class=\"col_heading level0 col3\" >LogLoss</th>\n",
       "      <th id=\"T_a40d2_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_a40d2_level0_col5\" class=\"col_heading level0 col5\" >Recall</th>\n",
       "      <th id=\"T_a40d2_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_a40d2_level0_col7\" class=\"col_heading level0 col7\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d2_level0_row0\" class=\"row_heading level0 row0\" >DummyClassifier: most_frequent</th>\n",
       "      <td id=\"T_a40d2_row0_col0\" class=\"data row0 col0\" >0.01s</td>\n",
       "      <td id=\"T_a40d2_row0_col1\" class=\"data row0 col1\" >28.97%</td>\n",
       "      <td id=\"T_a40d2_row0_col2\" class=\"data row0 col2\" >28.97%</td>\n",
       "      <td id=\"T_a40d2_row0_col3\" class=\"data row0 col3\" >25.6032</td>\n",
       "      <td id=\"T_a40d2_row0_col4\" class=\"data row0 col4\" >8.39%</td>\n",
       "      <td id=\"T_a40d2_row0_col5\" class=\"data row0 col5\" >28.97%</td>\n",
       "      <td id=\"T_a40d2_row0_col6\" class=\"data row0 col6\" >13.01%</td>\n",
       "      <td id=\"T_a40d2_row0_col7\" class=\"data row0 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d2_level0_row1\" class=\"row_heading level0 row1\" >DummyClassifier: uniform</th>\n",
       "      <td id=\"T_a40d2_row1_col0\" class=\"data row1 col0\" >0.01s</td>\n",
       "      <td id=\"T_a40d2_row1_col1\" class=\"data row1 col1\" >2.28%</td>\n",
       "      <td id=\"T_a40d2_row1_col2\" class=\"data row1 col2\" >2.27%</td>\n",
       "      <td id=\"T_a40d2_row1_col3\" class=\"data row1 col3\" >3.8067</td>\n",
       "      <td id=\"T_a40d2_row1_col4\" class=\"data row1 col4\" >11.30%</td>\n",
       "      <td id=\"T_a40d2_row1_col5\" class=\"data row1 col5\" >2.27%</td>\n",
       "      <td id=\"T_a40d2_row1_col6\" class=\"data row1 col6\" >3.19%</td>\n",
       "      <td id=\"T_a40d2_row1_col7\" class=\"data row1 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d2_level0_row2\" class=\"row_heading level0 row2\" >DummyClassifier: stratified</th>\n",
       "      <td id=\"T_a40d2_row2_col0\" class=\"data row2 col0\" >0.02s</td>\n",
       "      <td id=\"T_a40d2_row2_col1\" class=\"data row2 col1\" >11.49%</td>\n",
       "      <td id=\"T_a40d2_row2_col2\" class=\"data row2 col2\" >11.28%</td>\n",
       "      <td id=\"T_a40d2_row2_col3\" class=\"data row2 col3\" >31.9779</td>\n",
       "      <td id=\"T_a40d2_row2_col4\" class=\"data row2 col4\" >11.32%</td>\n",
       "      <td id=\"T_a40d2_row2_col5\" class=\"data row2 col5\" >11.28%</td>\n",
       "      <td id=\"T_a40d2_row2_col6\" class=\"data row2 col6\" >11.30%</td>\n",
       "      <td id=\"T_a40d2_row2_col7\" class=\"data row2 col7\" >49.84%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x137f0a410>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=Config.TBL_HILITE_COLOR\n",
    "results_defaults_styled = results_defaults_df[report_cols].style.map(lambda val: f'background-color: {hilite}',\n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_defaults_styled = results_defaults_styled.set_table_styles({\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_defaults_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad55b07-8a6b-4291-b583-12862846b9f0",
   "metadata": {},
   "source": [
    "#### Default Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c66344-0d73-429e-85eb-205a9ecd5722",
   "metadata": {},
   "source": [
    "We will now explore the selected models with out-of-the-box default settings of their hyperparameters to get a baseline per model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "744a6a88-2c2b-422d-ab1e-5a4edaab9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default models\n",
    "models_default = {\n",
    "    'LogisticRegression (Default)': LogisticRegression(random_state=Config.RANDOM_STATE),\n",
    "    'KNeighborsClassifier (Default)': KNeighborsClassifier(),\n",
    "    'RandomForestClassifier (Default)': RandomForestClassifier(random_state=Config.RANDOM_STATE),\n",
    "    'XGBClassifier (Default)': XGBClassifier(random_state=Config.RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8eb69be-88f4-4363-9e49-9c8b34489f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (Default): Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (Default): Done: 8.83s\n",
      "KNeighborsClassifier (Default): Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier (Default): Done: 38.98s\n",
      "RandomForestClassifier (Default): Starting (use_best=False)\n",
      "RandomForestClassifier (Default): Done: 35.92s\n",
      "XGBClassifier (Default): Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier (Default): Done: 46.18s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_default.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5dbde986-8ade-42db-9c5d-7afab3ccf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81c42370-9539-4502-8398-bba9f7536cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1ec16 th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_1ec16 th.col2 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_1ec16_row0_col2, #T_1ec16_row0_col3, #T_1ec16_row1_col2, #T_1ec16_row1_col3, #T_1ec16_row2_col2, #T_1ec16_row2_col3, #T_1ec16_row3_col2, #T_1ec16_row3_col3, #T_1ec16_row4_col2, #T_1ec16_row4_col3, #T_1ec16_row5_col2, #T_1ec16_row5_col3, #T_1ec16_row6_col2, #T_1ec16_row6_col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1ec16\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1ec16_level0_col0\" class=\"col_heading level0 col0\" >Train Time</th>\n",
       "      <th id=\"T_1ec16_level0_col1\" class=\"col_heading level0 col1\" >Train Accuracy</th>\n",
       "      <th id=\"T_1ec16_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "      <th id=\"T_1ec16_level0_col3\" class=\"col_heading level0 col3\" >LogLoss</th>\n",
       "      <th id=\"T_1ec16_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_1ec16_level0_col5\" class=\"col_heading level0 col5\" >Recall</th>\n",
       "      <th id=\"T_1ec16_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_1ec16_level0_col7\" class=\"col_heading level0 col7\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row0\" class=\"row_heading level0 row0\" >XGBClassifier (Default)</th>\n",
       "      <td id=\"T_1ec16_row0_col0\" class=\"data row0 col0\" >37.66s</td>\n",
       "      <td id=\"T_1ec16_row0_col1\" class=\"data row0 col1\" >54.15%</td>\n",
       "      <td id=\"T_1ec16_row0_col2\" class=\"data row0 col2\" >31.75%</td>\n",
       "      <td id=\"T_1ec16_row0_col3\" class=\"data row0 col3\" >2.5518</td>\n",
       "      <td id=\"T_1ec16_row0_col4\" class=\"data row0 col4\" >23.48%</td>\n",
       "      <td id=\"T_1ec16_row0_col5\" class=\"data row0 col5\" >31.75%</td>\n",
       "      <td id=\"T_1ec16_row0_col6\" class=\"data row0 col6\" >23.83%</td>\n",
       "      <td id=\"T_1ec16_row0_col7\" class=\"data row0 col7\" >70.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row1\" class=\"row_heading level0 row1\" >RandomForestClassifier (Default)</th>\n",
       "      <td id=\"T_1ec16_row1_col0\" class=\"data row1 col0\" >27.08s</td>\n",
       "      <td id=\"T_1ec16_row1_col1\" class=\"data row1 col1\" >98.39%</td>\n",
       "      <td id=\"T_1ec16_row1_col2\" class=\"data row1 col2\" >30.88%</td>\n",
       "      <td id=\"T_1ec16_row1_col3\" class=\"data row1 col3\" >5.3351</td>\n",
       "      <td id=\"T_1ec16_row1_col4\" class=\"data row1 col4\" >22.49%</td>\n",
       "      <td id=\"T_1ec16_row1_col5\" class=\"data row1 col5\" >30.88%</td>\n",
       "      <td id=\"T_1ec16_row1_col6\" class=\"data row1 col6\" >23.37%</td>\n",
       "      <td id=\"T_1ec16_row1_col7\" class=\"data row1 col7\" >67.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression (Default)</th>\n",
       "      <td id=\"T_1ec16_row2_col0\" class=\"data row2 col0\" >8.51s</td>\n",
       "      <td id=\"T_1ec16_row2_col1\" class=\"data row2 col1\" >29.20%</td>\n",
       "      <td id=\"T_1ec16_row2_col2\" class=\"data row2 col2\" >29.37%</td>\n",
       "      <td id=\"T_1ec16_row2_col3\" class=\"data row2 col3\" >2.6369</td>\n",
       "      <td id=\"T_1ec16_row2_col4\" class=\"data row2 col4\" >14.32%</td>\n",
       "      <td id=\"T_1ec16_row2_col5\" class=\"data row2 col5\" >29.37%</td>\n",
       "      <td id=\"T_1ec16_row2_col6\" class=\"data row2 col6\" >15.00%</td>\n",
       "      <td id=\"T_1ec16_row2_col7\" class=\"data row2 col7\" >63.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row3\" class=\"row_heading level0 row3\" >DummyClassifier: most_frequent</th>\n",
       "      <td id=\"T_1ec16_row3_col0\" class=\"data row3 col0\" >0.01s</td>\n",
       "      <td id=\"T_1ec16_row3_col1\" class=\"data row3 col1\" >28.97%</td>\n",
       "      <td id=\"T_1ec16_row3_col2\" class=\"data row3 col2\" >28.97%</td>\n",
       "      <td id=\"T_1ec16_row3_col3\" class=\"data row3 col3\" >25.6032</td>\n",
       "      <td id=\"T_1ec16_row3_col4\" class=\"data row3 col4\" >8.39%</td>\n",
       "      <td id=\"T_1ec16_row3_col5\" class=\"data row3 col5\" >28.97%</td>\n",
       "      <td id=\"T_1ec16_row3_col6\" class=\"data row3 col6\" >13.01%</td>\n",
       "      <td id=\"T_1ec16_row3_col7\" class=\"data row3 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row4\" class=\"row_heading level0 row4\" >KNeighborsClassifier (Default)</th>\n",
       "      <td id=\"T_1ec16_row4_col0\" class=\"data row4 col0\" >0.08s</td>\n",
       "      <td id=\"T_1ec16_row4_col1\" class=\"data row4 col1\" >41.40%</td>\n",
       "      <td id=\"T_1ec16_row4_col2\" class=\"data row4 col2\" >22.09%</td>\n",
       "      <td id=\"T_1ec16_row4_col3\" class=\"data row4 col3\" >20.6385</td>\n",
       "      <td id=\"T_1ec16_row4_col4\" class=\"data row4 col4\" >16.36%</td>\n",
       "      <td id=\"T_1ec16_row4_col5\" class=\"data row4 col5\" >22.09%</td>\n",
       "      <td id=\"T_1ec16_row4_col6\" class=\"data row4 col6\" >17.86%</td>\n",
       "      <td id=\"T_1ec16_row4_col7\" class=\"data row4 col7\" >56.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row5\" class=\"row_heading level0 row5\" >DummyClassifier: uniform</th>\n",
       "      <td id=\"T_1ec16_row5_col0\" class=\"data row5 col0\" >0.01s</td>\n",
       "      <td id=\"T_1ec16_row5_col1\" class=\"data row5 col1\" >2.28%</td>\n",
       "      <td id=\"T_1ec16_row5_col2\" class=\"data row5 col2\" >2.27%</td>\n",
       "      <td id=\"T_1ec16_row5_col3\" class=\"data row5 col3\" >3.8067</td>\n",
       "      <td id=\"T_1ec16_row5_col4\" class=\"data row5 col4\" >11.30%</td>\n",
       "      <td id=\"T_1ec16_row5_col5\" class=\"data row5 col5\" >2.27%</td>\n",
       "      <td id=\"T_1ec16_row5_col6\" class=\"data row5 col6\" >3.19%</td>\n",
       "      <td id=\"T_1ec16_row5_col7\" class=\"data row5 col7\" >50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ec16_level0_row6\" class=\"row_heading level0 row6\" >DummyClassifier: stratified</th>\n",
       "      <td id=\"T_1ec16_row6_col0\" class=\"data row6 col0\" >0.02s</td>\n",
       "      <td id=\"T_1ec16_row6_col1\" class=\"data row6 col1\" >11.49%</td>\n",
       "      <td id=\"T_1ec16_row6_col2\" class=\"data row6 col2\" >11.28%</td>\n",
       "      <td id=\"T_1ec16_row6_col3\" class=\"data row6 col3\" >31.9779</td>\n",
       "      <td id=\"T_1ec16_row6_col4\" class=\"data row6 col4\" >11.32%</td>\n",
       "      <td id=\"T_1ec16_row6_col5\" class=\"data row6 col5\" >11.28%</td>\n",
       "      <td id=\"T_1ec16_row6_col6\" class=\"data row6 col6\" >11.30%</td>\n",
       "      <td id=\"T_1ec16_row6_col7\" class=\"data row6 col7\" >49.84%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x137f09750>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=Config.TBL_HILITE_COLOR\n",
    "results_defaults_styled = results_defaults_df[report_cols].style.map(lambda val: f'background-color: {hilite}',\n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_defaults_styled = results_defaults_styled.set_table_styles({\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_defaults_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec75288c-653c-44a3-b465-cac3f869b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_defaults_styled, Config.IMAGE_DIR / 'table_models_defaults.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f2423-3513-4e2e-b864-487cf540f93e",
   "metadata": {},
   "source": [
    "### Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39f421c5-bc59-47db-8b30-f534a18f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "VERBOSE=2             # 0: None, 1: Iteration end, 2: Iteration scores\n",
    "JOBS=-1               # Use all cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c673584b-bc59-43da-908c-335324579987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_tuned = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols_tuned = ['params', 'Train Time', \n",
    "                     'Train Accuracy', 'Test Accuracy', 'LogLoss',\n",
    "                     'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1dd0954-4948-4d9f-ad5c-6b37e1a75cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the candidate models with starting params\n",
    "models_tuned = {\n",
    "    \n",
    "    'LogisticRegression': LogisticRegression(penalty='l1', solver='saga', max_iter=1000, \n",
    "                                             verbose=VERBOSE, n_jobs=JOBS, random_state=Config.RANDOM_STATE),\n",
    "\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                                     min_samples_leaf=5, min_samples_split=25, \n",
    "                                                     random_state=Config.RANDOM_STATE, \n",
    "                                                     verbose=VERBOSE, n_jobs=JOBS),\n",
    "\n",
    "    'XGBClassifier': XGBClassifier(n_estimators=100, objective=\"multi:softprob\", \n",
    "                                   n_jobs=JOBS, random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bc344af-5cea-482f-a14b-fe3f0bbb7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 60 epochs took 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Done: 17.13s\n",
      "RandomForestClassifier: Starting (use_best=False)\n",
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100building tree 18 of 100\n",
      "\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100building tree 22 of 100\n",
      "\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100building tree 26 of 100\n",
      "\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Done: 8.62s\n",
      "XGBClassifier: Starting (use_best=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier: Done: 53.90s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_tuned.items():\n",
    "    results_tuned[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4472a293-5e12-410f-97c3-42e4d1193b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_tuned_df = pd.DataFrame(results_tuned).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14d4a2a2-9414-4556-906f-223f90ade436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e8c5 td.col0 {\n",
       "  max-width: 300px;\n",
       "  white-space: normal;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6e8c5 th.col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_6e8c5 th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_6e8c5_row0_col3, #T_6e8c5_row0_col4, #T_6e8c5_row1_col3, #T_6e8c5_row1_col4, #T_6e8c5_row2_col3, #T_6e8c5_row2_col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e8c5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e8c5_level0_col0\" class=\"col_heading level0 col0\" >params</th>\n",
       "      <th id=\"T_6e8c5_level0_col1\" class=\"col_heading level0 col1\" >Train Time</th>\n",
       "      <th id=\"T_6e8c5_level0_col2\" class=\"col_heading level0 col2\" >Train Accuracy</th>\n",
       "      <th id=\"T_6e8c5_level0_col3\" class=\"col_heading level0 col3\" >Test Accuracy</th>\n",
       "      <th id=\"T_6e8c5_level0_col4\" class=\"col_heading level0 col4\" >LogLoss</th>\n",
       "      <th id=\"T_6e8c5_level0_col5\" class=\"col_heading level0 col5\" >Precision</th>\n",
       "      <th id=\"T_6e8c5_level0_col6\" class=\"col_heading level0 col6\" >Recall</th>\n",
       "      <th id=\"T_6e8c5_level0_col7\" class=\"col_heading level0 col7\" >F1</th>\n",
       "      <th id=\"T_6e8c5_level0_col8\" class=\"col_heading level0 col8\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e8c5_level0_row0\" class=\"row_heading level0 row0\" >RandomForestClassifier</th>\n",
       "      <td id=\"T_6e8c5_row0_col0\" class=\"data row0 col0\" >{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 2, 'warm_start': False}</td>\n",
       "      <td id=\"T_6e8c5_row0_col1\" class=\"data row0 col1\" >6.03s</td>\n",
       "      <td id=\"T_6e8c5_row0_col2\" class=\"data row0 col2\" >39.48%</td>\n",
       "      <td id=\"T_6e8c5_row0_col3\" class=\"data row0 col3\" >32.01%</td>\n",
       "      <td id=\"T_6e8c5_row0_col4\" class=\"data row0 col4\" >2.5399</td>\n",
       "      <td id=\"T_6e8c5_row0_col5\" class=\"data row0 col5\" >23.59%</td>\n",
       "      <td id=\"T_6e8c5_row0_col6\" class=\"data row0 col6\" >32.01%</td>\n",
       "      <td id=\"T_6e8c5_row0_col7\" class=\"data row0 col7\" >20.52%</td>\n",
       "      <td id=\"T_6e8c5_row0_col8\" class=\"data row0 col8\" >71.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e8c5_level0_row1\" class=\"row_heading level0 row1\" >XGBClassifier</th>\n",
       "      <td id=\"T_6e8c5_row1_col0\" class=\"data row1 col0\" >{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}</td>\n",
       "      <td id=\"T_6e8c5_row1_col1\" class=\"data row1 col1\" >37.70s</td>\n",
       "      <td id=\"T_6e8c5_row1_col2\" class=\"data row1 col2\" >54.15%</td>\n",
       "      <td id=\"T_6e8c5_row1_col3\" class=\"data row1 col3\" >31.75%</td>\n",
       "      <td id=\"T_6e8c5_row1_col4\" class=\"data row1 col4\" >2.5518</td>\n",
       "      <td id=\"T_6e8c5_row1_col5\" class=\"data row1 col5\" >23.48%</td>\n",
       "      <td id=\"T_6e8c5_row1_col6\" class=\"data row1 col6\" >31.75%</td>\n",
       "      <td id=\"T_6e8c5_row1_col7\" class=\"data row1 col7\" >23.83%</td>\n",
       "      <td id=\"T_6e8c5_row1_col8\" class=\"data row1 col8\" >70.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e8c5_level0_row2\" class=\"row_heading level0 row2\" >LogisticRegression</th>\n",
       "      <td id=\"T_6e8c5_row2_col0\" class=\"data row2 col0\" >{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga', 'tol': 0.0001, 'verbose': 2, 'warm_start': False}</td>\n",
       "      <td id=\"T_6e8c5_row2_col1\" class=\"data row2 col1\" >16.81s</td>\n",
       "      <td id=\"T_6e8c5_row2_col2\" class=\"data row2 col2\" >29.20%</td>\n",
       "      <td id=\"T_6e8c5_row2_col3\" class=\"data row2 col3\" >29.36%</td>\n",
       "      <td id=\"T_6e8c5_row2_col4\" class=\"data row2 col4\" >2.6368</td>\n",
       "      <td id=\"T_6e8c5_row2_col5\" class=\"data row2 col5\" >14.41%</td>\n",
       "      <td id=\"T_6e8c5_row2_col6\" class=\"data row2 col6\" >29.36%</td>\n",
       "      <td id=\"T_6e8c5_row2_col7\" class=\"data row2 col7\" >14.99%</td>\n",
       "      <td id=\"T_6e8c5_row2_col8\" class=\"data row2 col8\" >63.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x137f276d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=Config.TBL_HILITE_COLOR\n",
    "results_tuned_styled = results_tuned_df[report_cols_tuned].style.map(lambda val: f'background-color: {hilite}', \n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_tuned_styled = results_tuned_styled.set_table_styles({\n",
    "    'params': [{'selector': 'td', 'props': [('max-width', '300px'), \n",
    "                                  ('white-space', 'normal'), \n",
    "                                  ('word-wrap', 'break-word')]}],\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_tuned_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bdfbdc72-870d-40e0-b354-32f7848730cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_tuned_styled, Config.IMAGE_DIR / 'table_models_tuned.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24849f0-e427-4247-9ccd-e3f9cab73961",
   "metadata": {},
   "source": [
    "## Model Tuning: BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0194e986-f671-4410-aa82-dab2daa910b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesSearchCV Tuning parameters\n",
    "CV=3             # cross-validation splitting strategy: StratifiedKFold=3\n",
    "VERBOSE=2        # 0: None, 1: Iteration end, 2: Iteration scores\n",
    "JOBS=-1          # Use all cores\n",
    "#ITERATIONS=20    # Num of param settings that are sampled (Def=50). Trades off runtime vs quality of the solution\n",
    "ITERATIONS=2     # Num of param settings that are sampled (Def=50). Trades off runtime vs quality of the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a8758c9-3d57-424e-bc24-1917bce4665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_CV = {}\n",
    "\n",
    "# let's start saving the results for reporting out\n",
    "results_tuned = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols_CV = ['best_params', 'Train Time', \n",
    "                  'Train Accuracy', 'Test Accuracy', 'LogLoss',\n",
    "                  'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f77631a6-bb85-49f8-b0a9-3bcf4b25291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our models for BayesSearchCV\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=Config.RANDOM_STATE),\n",
    "    'XGBClassifier': XGBClassifier(objective=\"multi:softprob\", random_state=Config.RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Define the search spaces for hyperparameter tuning \n",
    "model_search_spaces = {\n",
    "    \n",
    "    # Define search spaces for RandomForestClassifier\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': Integer(50, 100),\n",
    "        'max_depth': Integer(3, 20),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical(['sqrt', 'log2', None]),       # None=n_features\n",
    "    },\n",
    "    \n",
    "    # Define search spaces for XGBClassifier\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': Integer(50, 1000),\n",
    "        'max_depth': Integer(3, 100),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'colsample_bytree': Real(0.5, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f9081fe-62e8-4daf-a3d1-2125fbafaa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Starting BayesSearchCV optimization (3-fold)\n",
      "RandomForestClassifier: Starting (use_best=True)\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "... Iteration #1 Best(score: 2.5545, best_params: [10, None, 9, 8, 84])\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "... Iteration #2 Best(score: 2.6826, best_params: [10, None, 9, 8, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: RandomForestClassifier: Fitted: 128.68557596206665 secs\n",
      "DEBUG: RandomForestClassifier: Best Model=RandomForestClassifier(max_depth=10, max_features=None, min_samples_leaf=9,\n",
      "                       min_samples_split=8, n_estimators=84, random_state=42)\n",
      "DEBUG: RandomForestClassifier: Best Params=OrderedDict([('max_depth', 10), ('max_features', None), ('min_samples_leaf', 9), ('min_samples_split', 8), ('n_estimators', 84)])\n",
      "DEBUG: RandomForestClassifier: Got preds/probs\n",
      "DEBUG: RandomForestClassifier: cm.shape: (45, 45)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "DEBUG: RandomForestClassifier: Got metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Done: 2m 11.23s\n",
      "RandomForestClassifier: Done BayesSearchCV optimization (3-fold)\n",
      "XGBClassifier: Starting BayesSearchCV optimization (3-fold)\n",
      "XGBClassifier: Starting (use_best=True)\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END max_depth=17, max_features=None, min_samples_leaf=4, min_samples_split=19, n_estimators=93; total time=  51.1s\n",
      "... Iteration #1 Best(score: 3.2288, best_params: [0.4160029192647807, 0.8638628715886625, 0.2387586688716479, 34, 7, 443, 1.440064730980368e-06, 0.7482570377261556, 0.6522316555182531])\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "... Iteration #2 Best(score: 2.5597, best_params: [0.8390144719977516, 0.9416576386904312, 0.02806554771929606, 95, 9, 109, 1.7570205641667407e-08, 1.7500432085329334e-05, 0.8178645509395852])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: XGBClassifier: Fitted: 487.3132338523865 secs\n",
      "DEBUG: XGBClassifier: Best Model=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=0.8390144719977516, colsample_bynode=None,\n",
      "              colsample_bytree=0.9416576386904312, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.02806554771929606,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=95, max_leaves=None,\n",
      "              min_child_weight=9, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=109, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "DEBUG: XGBClassifier: Best Params=OrderedDict([('colsample_bylevel', 0.8390144719977516), ('colsample_bytree', 0.9416576386904312), ('learning_rate', 0.02806554771929606), ('max_depth', 95), ('min_child_weight', 9), ('n_estimators', 109), ('reg_alpha', 1.7570205641667407e-08), ('reg_lambda', 1.7500432085329334e-05), ('subsample', 0.8178645509395852)])\n",
      "DEBUG: XGBClassifier: Got preds/probs\n",
      "DEBUG: XGBClassifier: cm.shape: (45, 45)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "DEBUG: XGBClassifier: Got metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier: Done: 8m 32.05s\n",
      "XGBClassifier: Done BayesSearchCV optimization (3-fold)\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models.items():\n",
    "    \n",
    "    print(f'{name}: Starting BayesSearchCV optimization ({CV}-fold)', flush=True)\n",
    "    opt = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=model_search_spaces[name],\n",
    "        scoring = 'neg_log_loss',\n",
    "        n_iter=ITERATIONS,\n",
    "        cv=CV,\n",
    "        n_jobs=JOBS,\n",
    "        random_state=Config.RANDOM_STATE,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "\n",
    "    results_CV[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test, optimizer=opt)\n",
    "\n",
    "    print(f'{name}: Done BayesSearchCV optimization ({CV}-fold)', flush=True)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a7ef6dc-c254-49f7-9bf2-4f003fd40fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_CV_df = pd.DataFrame(results_CV).T.sort_values(by=['Test Accuracy', 'LogLoss'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3adcab8-e0c6-49b7-ba43-c6d8cbc14c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_10faa td.col0 {\n",
       "  max-width: 300px;\n",
       "  white-space: normal;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_10faa th.col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_10faa th.col3 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_10faa_row0_col3, #T_10faa_row0_col4, #T_10faa_row1_col3, #T_10faa_row1_col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_10faa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_10faa_level0_col0\" class=\"col_heading level0 col0\" >best_params</th>\n",
       "      <th id=\"T_10faa_level0_col1\" class=\"col_heading level0 col1\" >Train Time</th>\n",
       "      <th id=\"T_10faa_level0_col2\" class=\"col_heading level0 col2\" >Train Accuracy</th>\n",
       "      <th id=\"T_10faa_level0_col3\" class=\"col_heading level0 col3\" >Test Accuracy</th>\n",
       "      <th id=\"T_10faa_level0_col4\" class=\"col_heading level0 col4\" >LogLoss</th>\n",
       "      <th id=\"T_10faa_level0_col5\" class=\"col_heading level0 col5\" >Precision</th>\n",
       "      <th id=\"T_10faa_level0_col6\" class=\"col_heading level0 col6\" >Recall</th>\n",
       "      <th id=\"T_10faa_level0_col7\" class=\"col_heading level0 col7\" >F1</th>\n",
       "      <th id=\"T_10faa_level0_col8\" class=\"col_heading level0 col8\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_10faa_level0_row0\" class=\"row_heading level0 row0\" >XGBClassifier</th>\n",
       "      <td id=\"T_10faa_row0_col0\" class=\"data row0 col0\" >{'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.9416576386904312, 'learning_rate': 0.02806554771929606, 'max_depth': 95, 'min_child_weight': 9, 'n_estimators': 109, 'reg_alpha': 1.7570205641667407e-08, 'reg_lambda': 1.7500432085329334e-05, 'subsample': 0.8178645509395852}</td>\n",
       "      <td id=\"T_10faa_row0_col1\" class=\"data row0 col1\" >8m 7.31s</td>\n",
       "      <td id=\"T_10faa_row0_col2\" class=\"data row0 col2\" >46.52%</td>\n",
       "      <td id=\"T_10faa_row0_col3\" class=\"data row0 col3\" >32.62%</td>\n",
       "      <td id=\"T_10faa_row0_col4\" class=\"data row0 col4\" >2.5408</td>\n",
       "      <td id=\"T_10faa_row0_col5\" class=\"data row0 col5\" >23.82%</td>\n",
       "      <td id=\"T_10faa_row0_col6\" class=\"data row0 col6\" >32.62%</td>\n",
       "      <td id=\"T_10faa_row0_col7\" class=\"data row0 col7\" >23.13%</td>\n",
       "      <td id=\"T_10faa_row0_col8\" class=\"data row0 col8\" >71.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10faa_level0_row1\" class=\"row_heading level0 row1\" >RandomForestClassifier</th>\n",
       "      <td id=\"T_10faa_row1_col0\" class=\"data row1 col0\" >{'max_depth': 10, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 8, 'n_estimators': 84}</td>\n",
       "      <td id=\"T_10faa_row1_col1\" class=\"data row1 col1\" >2m 8.69s</td>\n",
       "      <td id=\"T_10faa_row1_col2\" class=\"data row1 col2\" >33.34%</td>\n",
       "      <td id=\"T_10faa_row1_col3\" class=\"data row1 col3\" >31.40%</td>\n",
       "      <td id=\"T_10faa_row1_col4\" class=\"data row1 col4\" >2.5508</td>\n",
       "      <td id=\"T_10faa_row1_col5\" class=\"data row1 col5\" >21.36%</td>\n",
       "      <td id=\"T_10faa_row1_col6\" class=\"data row1 col6\" >31.40%</td>\n",
       "      <td id=\"T_10faa_row1_col7\" class=\"data row1 col7\" >19.52%</td>\n",
       "      <td id=\"T_10faa_row1_col8\" class=\"data row1 col8\" >70.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x139b19f50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format the output to hilite results\n",
    "hilite=Config.TBL_HILITE_COLOR\n",
    "results_CV_styled = results_CV_df[report_cols_CV].style.map(lambda val: f'background-color: {hilite}', \n",
    "                                                                     subset=['Test Accuracy','LogLoss'])\n",
    "results_CV_styled = results_CV_styled.set_table_styles({\n",
    "    'best_params': [{'selector': 'td', 'props': [('max-width', '300px'), \n",
    "                                                 ('white-space', 'normal'), \n",
    "                                                 ('word-wrap', 'break-word')]}],\n",
    "    'LogLoss': [{'selector': 'th', 'props': [('background-color', hilite)]}],\n",
    "    'Test Accuracy': [{'selector': 'th', 'props': [('background-color', hilite)]}]\n",
    "}, overwrite=False)\n",
    "results_CV_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6107a486-a315-4bcf-9bfb-d78fa6d0082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_CV_styled, Config.IMAGE_DIR / 'table_models_CV.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35de77-1361-462b-beee-eee1c8bbe113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

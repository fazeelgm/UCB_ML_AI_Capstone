{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800f300e-1c9d-4f8e-9bce-aa31778a3bbc",
   "metadata": {},
   "source": [
    "# Capstone: Exploratory Prediction Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b05fd2b-87c4-4db0-9bb5-1ae0748656bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Import utilities\n",
    "# import pathlib\n",
    "import time\n",
    "\n",
    "# Export dataFrame's as images\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# import project utils\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import data_utils\n",
    "from data_utils import Config\n",
    "\n",
    "import graph_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, log_loss\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4214fe9c-8a7e-46d6-a79e-48fe4150289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c6b335-5290-483d-8aa6-5b7f9b7b5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_secs_to_msg(lapse_time_secs, mins_label='m', secs_label='s'):\n",
    "    if lapse_time_secs <= 60:\n",
    "        return f'{lapse_time_secs%60:.2f}{secs_label}'\n",
    "    else:\n",
    "        return f'{lapse_time_secs//60:,.0f}{mins_label} {lapse_time_secs%60:.2f}{secs_label}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814d6a5-3ae8-43f1-b00f-5b22986f3267",
   "metadata": {},
   "source": [
    "## The Data: San Francisco Police Department Incident Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd64605-3a3b-480b-be39-711b70beb7cc",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3250ab5b-8240-4f47-9438-aecea04d69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sample file: ../data/incidents_clean_10_pct.csv\n"
     ]
    }
   ],
   "source": [
    "# Which dataset to work from?\n",
    "\n",
    "# sample_file = data_utils.select_sample_csv_file(pct=100)\n",
    "sample_file = data_utils.select_sample_csv_file(pct=10)\n",
    "print(f'Selected sample file: {sample_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f7eb17-698f-4eba-aebc-c2893f443e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ../data/incidents_clean_10_pct.csv ... Done: 89,458 rows, 37 columns\n",
      "... Converting datetime to timeseries ... Done\n",
      "... Setting index to datetime ... Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "current_raw_df, current_clean_df = data_utils.get_clean_data_from_csv(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49438aea-557f-49a0-9caf-2a230ea378f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing ... \n",
      "... Dropping unwanted columns ... \n",
      "... preprocess_drop_cols: Column Unnamed: 0 dropped\n",
      "... preprocess_drop_cols: Column esncag_-_boundary_file dropped\n",
      "... preprocess_drop_cols: Column central_market/tenderloin_boundary_polygon_-_updated dropped\n",
      "... preprocess_drop_cols: Column civic_center_harm_reduction_project_boundary dropped\n",
      "... preprocess_drop_cols: Column hsoc_zones_as_of_2018-06-05 dropped\n",
      "... preprocess_drop_cols: Column invest_in_neighborhoods_(iin)_areas dropped\n",
      "... preprocess_drop_cols: Column report_type_code dropped\n",
      "... preprocess_drop_cols: Column report_type_description dropped\n",
      "... preprocess_drop_cols: Column filed_online dropped\n",
      "... preprocess_drop_cols: Column intersection dropped\n",
      "... preprocess_drop_cols: Column cnn dropped\n",
      "... preprocess_drop_cols: Column point dropped\n",
      "... preprocess_drop_cols: Column supervisor_district dropped\n",
      "... preprocess_drop_cols: Column supervisor_district_2012 dropped\n",
      "... preprocess_drop_cols: Column current_supervisor_districts dropped\n",
      "... preprocess_drop_cols: Column incident_datetime dropped\n",
      "... preprocess_drop_cols: Column report_datetime dropped\n",
      "... preprocess_drop_cols: Column incident_id dropped\n",
      "... preprocess_drop_cols: Column incident_code dropped\n",
      "... preprocess_drop_cols: Column row_id dropped\n",
      "... preprocess_drop_cols: Column incident_number dropped\n",
      "... preprocess_drop_cols: Column cad_number dropped\n",
      "... preprocess_drop_cols: Column incident_subcategory dropped\n",
      "... preprocess_drop_cols: Column incident_description dropped\n",
      "... preprocess_drop_cols: Column current_police_districts dropped\n",
      "... preprocess_drop_cols: Column neighborhoods dropped\n",
      "... Done\n",
      "... Removing resolution types: \"Unfounded\", \"Exceptional Adult\" ... \n",
      "... Removing police_district types: \"Out of SF\" ... \n",
      "... Renaming column: \"analysis_neighborhood\" -> \"neighborhood\" ... \n",
      "... Renaming columns: Dropping \"incident_*\" from column names ... \n",
      "... Removing rows with nulls (dropna) ... \n",
      "... Done\n",
      "Done: Start: (89458, 36), End: (82888, 10) -> Rows removed: 6,570 rows (7.34%)\n"
     ]
    }
   ],
   "source": [
    "data = data_utils.preprocess_data(current_raw_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796600d8-4dc4-4367-8bdd-48602641b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data artifacts (in-place) ... \n",
      "... Category column:\n",
      "    ...\"Human Trafficking*\"\n",
      "    ...\"Motor Vehicle Theft\"\n",
      "    ...\"Weapons Offence\"\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Fix data value artifacts that were discovered during EDA\n",
    "data = data_utils.fix_data_artifacts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0593a1a6-d608-4168-ab60-698d8e3a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             82888 non-null  object \n",
      " 1   time             82888 non-null  object \n",
      " 2   year             82888 non-null  int64  \n",
      " 3   day_of_week      82888 non-null  object \n",
      " 4   category         82888 non-null  object \n",
      " 5   resolution       82888 non-null  object \n",
      " 6   police_district  82888 non-null  object \n",
      " 7   neighborhood     82888 non-null  object \n",
      " 8   latitude         82888 non-null  float64\n",
      " 9   longitude        82888 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b6f7-2f63-409e-8a77-d95a82a599b2",
   "metadata": {},
   "source": [
    "## Summary of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62469-b0fa-405b-ae5e-9cf32c9994a4",
   "metadata": {},
   "source": [
    "After cleaning the data and performing basic EDA, we have established the following:\n",
    "\n",
    "1. Target variable `category`\n",
    "   * Evenly spread across time\n",
    "   * Incidence of crimes is extremely skewed/unbalanced by category. Larceny (29.02%) by far outweighing the other top-10 categories with each being in the single digits\n",
    "3. Features impacting `category`\n",
    "   * Affected by incident time and date components: date, time, day of week, month, year, etc\n",
    "   * Affected by police disctrict\n",
    "   * Affect by latitude and logitude (TODO: need visualization)\n",
    "4. We artificially removed nulls (TODO: will come back to impute data later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4580fda-167c-419e-94a4-466d884169d8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3693b1c-6a4c-4480-99c3-1afb183a1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>category</th>\n",
       "      <th>resolution</th>\n",
       "      <th>police_district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <td>2024/08/01</td>\n",
       "      <td>08:01</td>\n",
       "      <td>2024</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Other Miscellaneous</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Mission</td>\n",
       "      <td>Mission</td>\n",
       "      <td>37.768272</td>\n",
       "      <td>-122.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>23:30</td>\n",
       "      <td>2021</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>Open or Active</td>\n",
       "      <td>Northern</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>-122.432467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date   time  year day_of_week             category  \\\n",
       "datetime                                                                        \n",
       "2024-08-01 08:01:00  2024/08/01  08:01  2024    Thursday  Other Miscellaneous   \n",
       "2021-11-25 23:30:00  2021/11/25  23:30  2021    Thursday             Burglary   \n",
       "\n",
       "                         resolution police_district    neighborhood  \\\n",
       "datetime                                                              \n",
       "2024-08-01 08:01:00  Open or Active         Mission         Mission   \n",
       "2021-11-25 23:30:00  Open or Active        Northern  Haight Ashbury   \n",
       "\n",
       "                      latitude   longitude  \n",
       "datetime                                    \n",
       "2024-08-01 08:01:00  37.768272 -122.419983  \n",
       "2021-11-25 23:30:00  37.773757 -122.432467  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c52ff3-baa7-47e8-95e7-6b65ffd9424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             82888 non-null  object \n",
      " 1   time             82888 non-null  object \n",
      " 2   year             82888 non-null  int64  \n",
      " 3   day_of_week      82888 non-null  object \n",
      " 4   category         82888 non-null  object \n",
      " 5   resolution       82888 non-null  object \n",
      " 6   police_district  82888 non-null  object \n",
      " 7   neighborhood     82888 non-null  object \n",
      " 8   latitude         82888 non-null  float64\n",
      " 9   longitude        82888 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93db1b-4718-4bac-8a22-8aff944c3c64",
   "metadata": {},
   "source": [
    "### Encoding: Time-based columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6939cb5-85c3-4f3e-92f8-23347859bded",
   "metadata": {},
   "source": [
    "Let's unpack the date and time into their components that are still missing so there is less to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e80e1ca0-445e-4251-8672-a70c5ef40597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour'] = data.index.map(lambda x: x.hour)\n",
    "data['minute'] = data.index.map(lambda x: x.minute)\n",
    "data['day'] = data.index.map(lambda x: x.day)\n",
    "data['month'] = data.index.map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834113f-4129-4c28-9ca6-f2f5051b7b1e",
   "metadata": {},
   "source": [
    "Now let's encode day_of_week to numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba3c50f-bc77-4491-b663-4ea286c5774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dow = LabelEncoder()\n",
    "enc_dow.fit(data.day_of_week.unique())\n",
    "data['dow'] = enc_dow.transform(data.day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb03a71-9c9e-4bca-af32-b35f05db2e1e",
   "metadata": {},
   "source": [
    "Let's mark the redundant columns to be dropped after feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce4c19a-dbf1-49c6-8fc5-c91a4e72aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols = ['date', 'time', 'day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474b64-0486-4de0-9fe3-85dd1df87559",
   "metadata": {},
   "source": [
    "### Encoding: Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fb531-2e4c-4f36-bf09-00bc9ca6c0e3",
   "metadata": {},
   "source": [
    "We will also drop the resolution column since it doesn't impact crime prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d130971c-9f96-40c2-a973-bb5ada873544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolution\n",
       "Open or Active          66265\n",
       "Cite or Arrest Adult    16623\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.resolution.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b60a7a-4290-42c5-bdcc-12436361160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols.append('resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a27a2a-a4e1-46e6-aaaa-6462a88ef904",
   "metadata": {},
   "source": [
    "### Encoding: Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1887058d-290d-4de7-be1a-ad4790edc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cat = LabelEncoder()\n",
    "enc_cat.fit(data.category.unique())\n",
    "data.category = enc_cat.transform(data.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4357e80-34aa-426c-8360-15da700f3136",
   "metadata": {},
   "source": [
    "### Encoding: Police District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b918e7f-285b-4cd6-9960-7fe80b848c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pd = LabelEncoder()\n",
    "enc_pd.fit(data.police_district.unique())\n",
    "data['pd'] = enc_pd.transform(data.police_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b758e-6f91-45af-b590-f526a8d84033",
   "metadata": {},
   "source": [
    "### Encoding: Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82fb1300-2f74-4930-94ab-a5b161e4b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hood = LabelEncoder()\n",
    "enc_hood.fit(data.neighborhood.unique())\n",
    "data.neighborhood = enc_hood.transform(data.neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844c0b5-1967-46f3-b316-5f8e2a1e4e74",
   "metadata": {},
   "source": [
    "### Dropping Redundant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40759752-bd7b-40ee-9503-2778c2594c9f",
   "metadata": {},
   "source": [
    "We can now drop the redundant encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db644549-7780-4117-be95-207dde3eb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping encoded columns: ['date', 'time', 'day_of_week', 'resolution', 'police_district']\n"
     ]
    }
   ],
   "source": [
    "drop_encoded_cols.append('police_district')\n",
    "\n",
    "print(f'Dropping encoded columns: {drop_encoded_cols}')\n",
    "data.drop(columns=drop_encoded_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de363da7-290a-4a98-bee6-2760db2cb526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>pd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <td>2024</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>37.768272</td>\n",
       "      <td>-122.419983</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>-122.432467</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  category  neighborhood   latitude   longitude  \\\n",
       "datetime                                                                   \n",
       "2024-08-01 08:01:00  2024        26            18  37.768272 -122.419983   \n",
       "2021-11-25 23:30:00  2021         2             8  37.773757 -122.432467   \n",
       "\n",
       "                     hour  minute  day  month  dow  pd  \n",
       "datetime                                                \n",
       "2024-08-01 08:01:00     8       1    1      8    4   3  \n",
       "2021-11-25 23:30:00    23      30   25     11    4   4  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a45dd9e-7aa0-43c1-9d94-40d6287cb845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 82888 entries, 2024-08-01 08:01:00 to 2018-10-02 16:53:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   year          82888 non-null  int64  \n",
      " 1   category      82888 non-null  int64  \n",
      " 2   neighborhood  82888 non-null  int64  \n",
      " 3   latitude      82888 non-null  float64\n",
      " 4   longitude     82888 non-null  float64\n",
      " 5   hour          82888 non-null  int64  \n",
      " 6   minute        82888 non-null  int64  \n",
      " 7   day           82888 non-null  int64  \n",
      " 8   month         82888 non-null  int64  \n",
      " 9   dow           82888 non-null  int64  \n",
      " 10  pd            82888 non-null  int64  \n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7ab2c-d5a3-4d2a-b158-87ea45debe21",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d496dcd-171a-4d49-8807-11ffafa4b233",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac470dae-d362-45d4-911f-5906ce1e271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('category', axis='columns')\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9df7a80e-6033-412d-a282-ffa985f48904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode the features and drop the first value to reduce multicollinearity\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "140d725c-be87-47fd-b60d-6bee9e666ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project-wide random_state: 42\n"
     ]
    }
   ],
   "source": [
    "# Consistent random_state for the project\n",
    "print(f'Project-wide random_state: {Config.RANDOM_STATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f71f3ab-33fa-4ea3-bade-efc053e13870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=Config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1966aa94-1593-4fd3-a9af-f4501f0fa543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER TRAIN_TEST_SPLIT: Data(82888, 11), X_train(66310, 10), X_test(16578, 10), y_train(66310,), y_test(16578,)\n"
     ]
    }
   ],
   "source": [
    "print('AFTER TRAIN_TEST_SPLIT: Data{}, X_train{}, X_test{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a01d3fc6-d194-43b3-89eb-aa639586aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>datetime</th>\n",
       "      <th>2024-08-01 08:01:00</th>\n",
       "      <th>2021-11-25 23:30:00</th>\n",
       "      <th>2018-06-20 21:00:00</th>\n",
       "      <th>2022-07-06 12:41:00</th>\n",
       "      <th>2021-02-27 23:02:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2024.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>37.768272</td>\n",
       "      <td>37.773757</td>\n",
       "      <td>37.723642</td>\n",
       "      <td>37.777457</td>\n",
       "      <td>37.770063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-122.419983</td>\n",
       "      <td>-122.432467</td>\n",
       "      <td>-122.461251</td>\n",
       "      <td>-122.413158</td>\n",
       "      <td>-122.403878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "datetime      2024-08-01 08:01:00  2021-11-25 23:30:00  2018-06-20 21:00:00  \\\n",
       "year                  2024.000000          2021.000000          2018.000000   \n",
       "neighborhood            18.000000             8.000000            23.000000   \n",
       "latitude                37.768272            37.773757            37.723642   \n",
       "longitude             -122.419983          -122.432467          -122.461251   \n",
       "hour                     8.000000            23.000000            21.000000   \n",
       "minute                   1.000000            30.000000             0.000000   \n",
       "day                      1.000000            25.000000            20.000000   \n",
       "month                    8.000000            11.000000             6.000000   \n",
       "dow                      4.000000             4.000000             6.000000   \n",
       "pd                       3.000000             4.000000             8.000000   \n",
       "\n",
       "datetime      2022-07-06 12:41:00  2021-02-27 23:02:00  \n",
       "year                  2022.000000          2021.000000  \n",
       "neighborhood            33.000000            19.000000  \n",
       "latitude                37.777457            37.770063  \n",
       "longitude             -122.413158          -122.403878  \n",
       "hour                    12.000000            23.000000  \n",
       "minute                  41.000000             2.000000  \n",
       "day                      6.000000            27.000000  \n",
       "month                    7.000000             2.000000  \n",
       "dow                      6.000000             2.000000  \n",
       "pd                       9.000000             7.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot-check feature encoding\n",
    "X.T.iloc[:, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ffce7-ac24-4443-a5df-81a0449852c6",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6ed9a74-008a-4c0f-b2af-76e5f0e54793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER SCALING: Data(82888, 11), X_train_scaled(66310, 10), X_test_scaled(16578, 10), y_train(66310,), y_test(16578,)\n"
     ]
    }
   ],
   "source": [
    "# Scale the data - we'll use StandardScaler for the baseline model\n",
    "logging.debug('Scaling data')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('AFTER SCALING: Data{}, X_train_scaled{}, X_test_scaled{}, y_train{}, y_test{}'\n",
    "      .format(data.shape, X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df8b27-6969-4b14-b3e0-f4e351df67d0",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a3fbc-b034-4ced-a667-57713c0453a4",
   "metadata": {},
   "source": [
    "The task of classifying the incident types based on a set of historical attrirbutes (features) and predicting on similar attributes is a **multiclass classification** problem. We will now experiment on some ML models that are generally used for similar problems to see what would be the best choice for us.\n",
    "\n",
    "We will evaluate the following models:\n",
    "\n",
    "* Simple classification models\n",
    "  * `DummyClassifier` to get a baseline for our project\n",
    "  * `LogisticRegression` with L1 Regularization\n",
    "* Multiclass classifiers\n",
    "  * `KNeighborsClassifier`\n",
    "* Ensemble methods: Since our dataset has high variability with a lot of numerical and cagtegorical features with a range of mean and variance, we plan to employ ensemble methods and tune them for best results\n",
    "  * `RandomForestClassifier`\n",
    "  * `XGBClassifier`: We considered `XGLite` but selected XGBoost as it provides better model explainability features like SHAP values, which we expect to be able to use in explaining our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e74d3-390d-4b30-acc2-d685aa461d76",
   "metadata": {},
   "source": [
    "We will now evaluate different models for predicting the Crime Category from our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb217f2-ba53-4f9a-9fdf-c79a3deefe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'neighborhood', 'latitude', 'longitude', 'hour', 'minute',\n",
       "       'day', 'month', 'dow', 'pd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d149f8-5cf7-4455-9d03-e4018d377dd3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98634325-3d11-4c84-af0b-1cf89d0b122a",
   "metadata": {},
   "source": [
    "In this project, we are predicting or classifyig across 49 crime categories. We will use two evaluation metrics to compare our models:\n",
    "\n",
    "1. **Accuracy**: Measures the proportion of correct predictions over all predictions made. The accuracy benchmark is 1/49 or 2.04% given our crime categories\n",
    "2. **Log_Loss**: Measures the accuracy of a classifier by penalizing false classifications. It does this by taking the negative logarithm of the predicted probability for the true class. The goal is to minimize this loss, meaning that higher probabilities are assigned to the correct classes. Log loss is a powerful way to evaluate not just if the model is making the right predictions, but how confident it is in those predictions. A lower log loss indicates a model that is both accurate and confident.\n",
    "   * TODO: Benchmark???\n",
    "\n",
    "While accuracy provides a simple measure of correctness, log-loss offers a more nuanced view by considering how confident those predictions are. A model that predicts with 51% confidence for the correct class will have the same accuracy as one that predicts with 99% confidence, but their log loss will be very different. The 99%-confident model will have a much lower log loss.\n",
    "\n",
    "We'll use them together for a comprehensive evaluation and to learn more about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b0add-d301-47ef-afaf-781d93e3baba",
   "metadata": {},
   "source": [
    "The `build_results_row` utility function will be used to standardize the recording and reporting of our model exploration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d907e6-792a-4c8b-bd67-a4818a4a1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_row(name, model, Xtr, Xte, ytr, yte, use_best=False):\n",
    "    \"\"\"\n",
    "    Given the model and training/test sets, builds a row of metrics for reporting the results\n",
    "\n",
    "    :param name: Name/Description of model\n",
    "    :param model: Fully constructed model instance - will call fit() and predict() to get metrics\n",
    "    :param Xtr: X_train - scale before calling\n",
    "    :param Xte: X_test - scale before calling\n",
    "    :param ytr: Y_train set\n",
    "    :param yteL: Y_test set\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'{name}: Starting', flush=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(Xtr, ytr)\n",
    "\n",
    "    # if we're tuning then use best_estimator\n",
    "    if use_best:\n",
    "        clf = model.best_estimator_\n",
    "        logging.debug(f'{name}: Best Model={clf}')\n",
    "        logging.debug(f'{name}: Best Params={model.best_params_}')\n",
    "\n",
    "    # Save fit time\n",
    "    fit_time = time.time() - start_time\n",
    "    logging.debug(f'{name}: Fitted')\n",
    "\n",
    "    # get the predictions / probabilities\n",
    "    y_preds = clf.predict(Xte)\n",
    "    y_probs_full = clf.predict_proba(Xte)\n",
    "    y_probs = y_probs_full[:, 1]\n",
    "\n",
    "    # logging.debug(f'>>> yte.shape{yte.shape} y_preds.shape{y_preds.shape} y_probs_full.shape{y_probs_full.shape}')\n",
    "    # logging.debug(f'>>> {np.unique(yte)}')\n",
    "    # logging.debug(f'>>> {np.unique(y_preds)}')\n",
    "    # logging.debug(f'>>> {np.unique(y_probs_full)}')\n",
    "    logging.debug(f'{name}: Got preds/probs')\n",
    "\n",
    "    cm = confusion_matrix(yte, y_preds)\n",
    "    logging.debug(f'{name}: cm.shape: {cm.shape}')\n",
    "\n",
    "    # Get metrics\n",
    "    row = {\n",
    "        'Train Time': time_secs_to_msg(fit_time),\n",
    "        'Train Accuracy': f'{model.score(Xtr, ytr)*100:.2f}%',\n",
    "        'Test Accuracy': f'{model.score(Xte, yte)*100:.2f}%',\n",
    "        'Precision': f'{precision_score(yte, y_preds, average=\"weighted\")*100:.2f}%',  # for multi-class with imbalance\n",
    "        'Recall': f'{recall_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'F1': f'{f1_score(yte, y_preds, average=\"weighted\")*100:.2f}%',\n",
    "        'AUC': f'{roc_auc_score(yte, y_probs_full, average=\"weighted\", multi_class=\"ovr\")*100:.2f}%',    # faster with imbalanced multi-class cases\n",
    "        'Log_loss': f'{log_loss(yte, y_probs_full, labels=np.unique(yte)):.4f}',\n",
    "        'preds': y_preds,\n",
    "        'probs': y_probs,\n",
    "        'cm': cm,\n",
    "        # 'TN': f'{cm[0, 0]:,d}',\n",
    "        # 'FP': f'{cm[0, 1]:,d}',\n",
    "        # 'FN': f'{cm[1, 0]:,d}',\n",
    "        # 'TP': f'{cm[1, 1]:,d}',\n",
    "        'params': model.get_params(),\n",
    "        'best_params': None,\n",
    "        'best_model': clf,\n",
    "    }\n",
    "    if use_best:\n",
    "        row.update({'best_params': model.best_params_})\n",
    "        \n",
    "    logging.debug(f'{name}: Got metrics')\n",
    "    \n",
    "    print(f'{name}: Done: {time_secs_to_msg(time.time()-start_time)}')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc07dee-bc84-47e9-9534-8cb45ba5895c",
   "metadata": {},
   "source": [
    "### Establishing a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437c17b-eece-4bc1-ae29-ed0f023056e3",
   "metadata": {},
   "source": [
    "#### DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443338d-fa9b-4c0c-8bd1-e831c3244043",
   "metadata": {},
   "source": [
    "We will use the Scikit-Learn DummyClassifier method to get a baseline for our predictions using the different strategies provided by the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39f421c5-bc59-47db-8b30-f534a18f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5389318-135b-483b-a8a8-7cefd2223b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_defaults = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols = ['Train Time', \n",
    "               'Train Accuracy', 'Test Accuracy', 'Log_loss',\n",
    "               'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c554832-05bd-48c1-b3e3-6ab9a0e8ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DummyClassifier models we want to test\n",
    "models_dummy = {\n",
    "    'DummyClassifier: uniform': DummyClassifier(strategy='uniform', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: most_frequent': DummyClassifier(strategy='most_frequent', random_state=Config.RANDOM_STATE),\n",
    "    'DummyClassifier: stratified': DummyClassifier(strategy='stratified', random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7cb9c0f-d499-40b1-bf03-da7978cf2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: uniform: Starting\n",
      "DummyClassifier: uniform: Done: 1.11s\n",
      "DummyClassifier: most_frequent: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier: most_frequent: Done: 0.49s\n",
      "DummyClassifier: stratified: Starting\n",
      "DummyClassifier: stratified: Done: 2.60s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_dummy.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aefff5-68d8-4f56-9c4e-932a17b16c7f",
   "metadata": {},
   "source": [
    "The warning above is from the precision calculation within scikit-learn, and highlights that some labels have no predicted samples, which results in precision being undefined for those labels. We can ignore the warning since we're using accuracy as our key evaluation metric. We could use `prescion_score(zero_division=0)` to suppress the warning, but we'll ignore it instead to ensure we're aware of the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e04a9d6-78c2-44c0-be2c-3070b772558e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Log_loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: most_frequent</th>\n",
       "      <td>0.06s</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>25.6032</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>13.01%</td>\n",
       "      <td>50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: uniform</th>\n",
       "      <td>0.02s</td>\n",
       "      <td>2.28%</td>\n",
       "      <td>2.27%</td>\n",
       "      <td>3.8067</td>\n",
       "      <td>11.30%</td>\n",
       "      <td>2.27%</td>\n",
       "      <td>3.19%</td>\n",
       "      <td>50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: stratified</th>\n",
       "      <td>0.05s</td>\n",
       "      <td>11.49%</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>31.9779</td>\n",
       "      <td>11.32%</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>11.30%</td>\n",
       "      <td>49.84%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Train Time Train Accuracy Test Accuracy  \\\n",
       "DummyClassifier: most_frequent      0.06s         28.97%        28.97%   \n",
       "DummyClassifier: uniform            0.02s          2.28%         2.27%   \n",
       "DummyClassifier: stratified         0.05s         11.49%        11.28%   \n",
       "\n",
       "                               Log_loss Precision  Recall      F1     AUC  \n",
       "DummyClassifier: most_frequent  25.6032     8.39%  28.97%  13.01%  50.00%  \n",
       "DummyClassifier: uniform         3.8067    11.30%   2.27%   3.19%  50.00%  \n",
       "DummyClassifier: stratified     31.9779    11.32%  11.28%  11.30%  49.84%  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'Log_loss'], ascending=[False, True])\n",
    "\n",
    "results_defaults_df[report_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad55b07-8a6b-4291-b583-12862846b9f0",
   "metadata": {},
   "source": [
    "#### Default Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c66344-0d73-429e-85eb-205a9ecd5722",
   "metadata": {},
   "source": [
    "We will now explore the selected models with out-of-the-box default settings of their hyperparameters to get a baseline per model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "744a6a88-2c2b-422d-ab1e-5a4edaab9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default models\n",
    "models_default = {\n",
    "    'LogisticRegression: Default': LogisticRegression(random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8eb69be-88f4-4363-9e49-9c8b34489f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Default: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Default: Done: 29.91s\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_default.items():\n",
    "    results_defaults[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ac4aae04-91e8-48a8-b2e3-4e4e3d8b1be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Log_loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression: Default</th>\n",
       "      <td>29.27s</td>\n",
       "      <td>29.20%</td>\n",
       "      <td>29.37%</td>\n",
       "      <td>2.6369</td>\n",
       "      <td>14.32%</td>\n",
       "      <td>29.37%</td>\n",
       "      <td>15.00%</td>\n",
       "      <td>63.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: most_frequent</th>\n",
       "      <td>0.01s</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>25.6032</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>28.97%</td>\n",
       "      <td>13.01%</td>\n",
       "      <td>50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: uniform</th>\n",
       "      <td>0.08s</td>\n",
       "      <td>2.28%</td>\n",
       "      <td>2.27%</td>\n",
       "      <td>3.8067</td>\n",
       "      <td>11.30%</td>\n",
       "      <td>2.27%</td>\n",
       "      <td>3.19%</td>\n",
       "      <td>50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier: stratified</th>\n",
       "      <td>0.07s</td>\n",
       "      <td>11.49%</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>31.9779</td>\n",
       "      <td>11.32%</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>11.30%</td>\n",
       "      <td>49.84%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Train Time Train Accuracy Test Accuracy  \\\n",
       "LogisticRegression: Default        29.27s         29.20%        29.37%   \n",
       "DummyClassifier: most_frequent      0.01s         28.97%        28.97%   \n",
       "DummyClassifier: uniform            0.08s          2.28%         2.27%   \n",
       "DummyClassifier: stratified         0.07s         11.49%        11.28%   \n",
       "\n",
       "                               Log_loss Precision  Recall      F1     AUC  \n",
       "LogisticRegression: Default      2.6369    14.32%  29.37%  15.00%  63.14%  \n",
       "DummyClassifier: most_frequent  25.6032     8.39%  28.97%  13.01%  50.00%  \n",
       "DummyClassifier: uniform         3.8067    11.30%   2.27%   3.19%  50.00%  \n",
       "DummyClassifier: stratified     31.9779    11.32%  11.28%  11.30%  49.84%  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_defaults_df = pd.DataFrame(results_defaults).T.sort_values(by=['Test Accuracy', 'Log_loss'], ascending=[False, True])\n",
    "\n",
    "results_defaults_df[report_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec75288c-653c-44a3-b465-cac3f869b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_defaults_df[report_cols], data_utils.Config.IMAGE_DIR / 'table_models_defaults.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3c961-58d1-4262-9885-72217bb84eda",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c673584b-bc59-43da-908c-335324579987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start saving the results for reporting out\n",
    "results_tuned = {}\n",
    "\n",
    "# Reports won't print all the columns\n",
    "report_cols_tuned = ['params', 'Train Time', \n",
    "                     'Train Accuracy', 'Test Accuracy', 'Log_loss',\n",
    "                     'Precision', 'Recall', 'F1', 'AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b1dd0954-4948-4d9f-ad5c-6b37e1a75cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the default models\n",
    "models_tuned = {\n",
    "    'LogisticRegression: L1 / saga': LogisticRegression(penalty='l1', solver='saga', max_iter=1000, \n",
    "                                                        verbose=1, n_jobs=3, random_state=Config.RANDOM_STATE),\n",
    "    f'RandomForestClassifier: n_e={n_estimators}, mx_d={15}': RandomForestClassifier(n_estimators=n_estimators, max_depth=15,\n",
    "                                                              min_samples_leaf=5, min_samples_split=25, \n",
    "                                                              random_state=Config.RANDOM_STATE, \n",
    "                                                              verbose=1, n_jobs=2),\n",
    "    f'XGBClassifier: n_e={n_estimators}, mx_d={15}': XGBClassifier(n_estimators=n_estimators, objective=\"multi:softprob\", \n",
    "                        n_jobs=2, random_state=Config.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc344af-5cea-482f-a14b-fe3f0bbb7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: L1 / saga: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 60 epochs took 37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: L1 / saga: Done: 37.16s\n",
      "RandomForestClassifier: n_e=100, mx_d=15: Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: n_e=100, mx_d=15: Done: 17.18s\n",
      "XGBClassifier: n_e=100, mx_d=15: Starting\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# Get metrics row for the report - will fit() and predict() to generate metrics\n",
    "for name, model in models_tuned.items():\n",
    "    results_tuned[name] = build_results_row(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b33e5-9c46-4b76-ab51-63d9538ac91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results by highest Test Accuracy and lowest log_loss\n",
    "results_tuned_df = pd.DataFrame(results_tuned).T.sort_values(by=['Test Accuracy', 'Log_loss'], ascending=[False, True])\n",
    "\n",
    "#results_tuned_df[report_cols_tuned]\n",
    "\n",
    "\n",
    "results_tuned_styled = results_tuned_df[report_cols_tuned].style.set_table_styles(\n",
    "    [{'selector': 'td', 'props': [('max-width', '350px'), \n",
    "                                  ('white-space', 'normal'), \n",
    "                                  ('word-wrap', 'break-word')]}]\n",
    ")\n",
    "results_tuned_styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbdc72-870d-40e0-b354-32f7848730cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for final report\n",
    "if not Config.SUPPRESS_OUTPUT_FILES:\n",
    "    dfi.export(results_tuned_styled, data_utils.Config.IMAGE_DIR / 'table_models_tuned.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e88d91-3b51-47ae-970b-05228b4b5f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
